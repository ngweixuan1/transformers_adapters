{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Adapters_imdb_DAPT_noadapter.ipynb","provenance":[{"file_id":"1EBEXeMXrJzTxKolfR5FlWwkXY-2Y0tXe","timestamp":1619353799495},{"file_id":"15UqXWTJZ_3w_08vVNrUE8DPpdV_EBh1U","timestamp":1619347325811},{"file_id":"1S2xY76CG2puXMlww-LB6vf51JhAcVvhf","timestamp":1619336370224},{"file_id":"1qDkodosI-REs-LqRomx0fyzmtIliDwi1","timestamp":1619334473343},{"file_id":"1jkthCAgVbiEwPYMJ2FQzHtrpiI71P7np","timestamp":1619324777840}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"142b984e91784e82bfbae19e844f8261":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9b0ecca7d0a04cf99bb3f809f57035c2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_25254c06638e46df82db0ed1374f38ed","IPY_MODEL_3129f9d9dc51497aa7a58c1409965cbe"]}},"9b0ecca7d0a04cf99bb3f809f57035c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"25254c06638e46df82db0ed1374f38ed":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_739b93bf4f5a45a5ba63c8ab35abc958","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":898822,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":898822,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cc4713c0275040f7954c5109abd06911"}},"3129f9d9dc51497aa7a58c1409965cbe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_aef79ac3211440ce81ad7950866b074b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 899k/899k [00:02&lt;00:00, 331kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d1eb9c47de8945a3a51d15a0799a717d"}},"739b93bf4f5a45a5ba63c8ab35abc958":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"cc4713c0275040f7954c5109abd06911":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"aef79ac3211440ce81ad7950866b074b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d1eb9c47de8945a3a51d15a0799a717d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"40e0956ec9cb48eaa6c7a06aca6ba6bf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fe24092c9725462f8b64c65788febf0c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0bba2cdbd85343b98e78137868a90165","IPY_MODEL_a48e5d684a014707b299cd9aba0b7911"]}},"fe24092c9725462f8b64c65788febf0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0bba2cdbd85343b98e78137868a90165":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9216351abff44cbaadd1c8d42a4e6716","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6c40d5586b25492d8387ccf7e4b4bb68"}},"a48e5d684a014707b299cd9aba0b7911":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_67cf63ea7b3b452999fb6580dc57becd","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 456k/456k [00:01&lt;00:00, 383kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ed16c9df18684de5916b6a46694f80e6"}},"9216351abff44cbaadd1c8d42a4e6716":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6c40d5586b25492d8387ccf7e4b4bb68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"67cf63ea7b3b452999fb6580dc57becd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ed16c9df18684de5916b6a46694f80e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c44692fc23764a37a5cf18b120fd08d6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3fe3616d0afd4d57badcdffa5bb12614","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1c9064f5d29b43ed86f05892b6779f84","IPY_MODEL_dfe5a3e7a326474da0606ed8c3d5aa94"]}},"3fe3616d0afd4d57badcdffa5bb12614":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1c9064f5d29b43ed86f05892b6779f84":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_766eadada0a54c438bfe32a490b0a00f","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":2,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7e332dbe81d347f7a786ef5325008025"}},"dfe5a3e7a326474da0606ed8c3d5aa94":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_07dbde5be1594680a2e99a04bfdbce9e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2.00/2.00 [00:00&lt;00:00, 4.30B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_93093fe9d7ba40afa9471f719f69453f"}},"766eadada0a54c438bfe32a490b0a00f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7e332dbe81d347f7a786ef5325008025":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"07dbde5be1594680a2e99a04bfdbce9e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"93093fe9d7ba40afa9471f719f69453f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a623a68db8b64371843d166b472dced7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6ac88bd75eb04b97bcb9537103b1305b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_379a39cbfd674ab09bc5d3897c73f2dd","IPY_MODEL_21fbffaf198e4c00be89fa97a4c3758f"]}},"6ac88bd75eb04b97bcb9537103b1305b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"379a39cbfd674ab09bc5d3897c73f2dd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2c8d285a7792431ba313aac610ee2bfa","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":150,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":150,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5063865006054ed4870eae5816c68061"}},"21fbffaf198e4c00be89fa97a4c3758f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a2a30e3705cb4ddba37b5010391de25a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 150/150 [00:00&lt;00:00, 202B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3bfa9c182a6a4579a6beacbbe5f9cf4b"}},"2c8d285a7792431ba313aac610ee2bfa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5063865006054ed4870eae5816c68061":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a2a30e3705cb4ddba37b5010391de25a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3bfa9c182a6a4579a6beacbbe5f9cf4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cd4ebbf695054bbbbe7486ae1d2403f9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c6a4fc9eb31f491e9fe378d9d5a66a08","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e12624339d6d4035ab0bd999be936079","IPY_MODEL_2523d92959024a3bb627ba87a8ca8d48"]}},"c6a4fc9eb31f491e9fe378d9d5a66a08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e12624339d6d4035ab0bd999be936079":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_52a55d7f17c54134af4f9e897ed2ae36","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":185,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":185,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6a6a55847e52433b9f5882bfc312d23e"}},"2523d92959024a3bb627ba87a8ca8d48":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f2670f6204ef4b1fb92c860d67800fb4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 185/185 [00:00&lt;00:00, 646B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ab011dc5ea9b494982b8035d90040154"}},"52a55d7f17c54134af4f9e897ed2ae36":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6a6a55847e52433b9f5882bfc312d23e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f2670f6204ef4b1fb92c860d67800fb4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ab011dc5ea9b494982b8035d90040154":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"lZj-G8LIXLpj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619844288089,"user_tz":-480,"elapsed":14015,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}},"outputId":"469bb8da-706e-44ee-854c-2b3ff5e1ce1f"},"source":["# mount google drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","# log_dir='/content/gdrive/MyDrive/DL_Project/runs'\n","# !mkdir -p {log_dir}\n","# !mv ./runs/* {log_dir}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D61LwET3WrOD","executionInfo":{"status":"ok","timestamp":1619844319102,"user_tz":-480,"elapsed":45020,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}},"outputId":"f7063a80-773b-4bb8-beaa-b5ad50c35baf"},"source":["!pip install -U git+https://github.com/Adapter-Hub/adapter-transformers.git@v2\n","!pip install torch==1.7.1\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/Adapter-Hub/adapter-transformers.git@v2\n","  Cloning https://github.com/Adapter-Hub/adapter-transformers.git (to revision v2) to /tmp/pip-req-build-6ohjnnvw\n","  Running command git clone -q https://github.com/Adapter-Hub/adapter-transformers.git /tmp/pip-req-build-6ohjnnvw\n","  Running command git checkout -b v2 --track origin/v2\n","  Switched to a new branch 'v2'\n","  Branch 'v2' set up to track remote branch 'v2' from 'origin'.\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from adapter-transformers==2.0.0a1) (2.23.0)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 7.4MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from adapter-transformers==2.0.0a1) (3.10.1)\n","Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.7/dist-packages (from adapter-transformers==2.0.0a1) (3.0.12)\n","Requirement already satisfied, skipping upgrade: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from adapter-transformers==2.0.0a1) (4.41.1)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 21.0MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from adapter-transformers==2.0.0a1) (2019.12.20)\n","Requirement already satisfied, skipping upgrade: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from adapter-transformers==2.0.0a1) (1.19.5)\n","Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from adapter-transformers==2.0.0a1) (20.9)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->adapter-transformers==2.0.0a1) (3.0.4)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->adapter-transformers==2.0.0a1) (2020.12.5)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->adapter-transformers==2.0.0a1) (1.24.3)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->adapter-transformers==2.0.0a1) (2.10)\n","Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->adapter-transformers==2.0.0a1) (1.0.1)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->adapter-transformers==2.0.0a1) (1.15.0)\n","Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->adapter-transformers==2.0.0a1) (7.1.2)\n","Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->adapter-transformers==2.0.0a1) (3.7.4.3)\n","Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->adapter-transformers==2.0.0a1) (3.4.1)\n","Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->adapter-transformers==2.0.0a1) (2.4.7)\n","Building wheels for collected packages: adapter-transformers\n","  Building wheel for adapter-transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for adapter-transformers: filename=adapter_transformers-2.0.0a1-cp37-none-any.whl size=2097547 sha256=bfd64cda1051b81f66b72cebd1ef2b348657e44254f9678dfe68696f263c8a6b\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-ndbe2u23/wheels/11/c5/35/7017ef1a9923a73e9d8071801894534ab1fa662e38e23b78f1\n","Successfully built adapter-transformers\n","Installing collected packages: sacremoses, tokenizers, adapter-transformers\n","Successfully installed adapter-transformers-2.0.0a1 sacremoses-0.0.45 tokenizers-0.10.2\n","Collecting torch==1.7.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/5d/095ddddc91c8a769a68c791c019c5793f9c4456a688ddd235d6670924ecb/torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8MB)\n","\u001b[K     |███████████▌                    | 280.3MB 1.3MB/s eta 0:06:16\n","\u001b[31mERROR: Operation cancelled by user\u001b[0m\n","\u001b[?25h"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DPpEKGrz_iNF","executionInfo":{"status":"ok","timestamp":1619844323578,"user_tz":-480,"elapsed":49490,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}},"outputId":"30ca02a7-6e77-47f5-8873-e213d8f7f1c8"},"source":["import json, gc\n","import urllib.request\n","import numpy as np\n","import pandas as pd\n","import torch\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Using device:', device)\n","\n","from transformers import (\n","    MODEL_WITH_LM_HEAD_MAPPING,\n","    WEIGHTS_NAME,\n","    AdamW,\n","    AutoConfig,\n","    AutoModelWithLMHead,\n","    AutoTokenizer,\n","    PreTrainedModel,\n","    PreTrainedTokenizer,\n","    get_linear_schedule_with_warmup,\n","    RobertaTokenizer\n",")\n","from transformers import RobertaForSequenceClassification, RobertaModelWithHeads, RobertaConfig\n","from transformers import TrainingArguments, Trainer, EvalPrediction\n","\n","from sklearn import metrics\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","\n","from transformers import EarlyStoppingCallback\n","from transformers.integrations import TensorBoardCallback\n","from tensorflow import summary\n","import tensorflow\n","%load_ext tensorboard\n","import datetime"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using device: cuda\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wwRHoyT1Kwyl"},"source":["Dataset and Tokenizers"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":260,"referenced_widgets":["142b984e91784e82bfbae19e844f8261","9b0ecca7d0a04cf99bb3f809f57035c2","25254c06638e46df82db0ed1374f38ed","3129f9d9dc51497aa7a58c1409965cbe","739b93bf4f5a45a5ba63c8ab35abc958","cc4713c0275040f7954c5109abd06911","aef79ac3211440ce81ad7950866b074b","d1eb9c47de8945a3a51d15a0799a717d","40e0956ec9cb48eaa6c7a06aca6ba6bf","fe24092c9725462f8b64c65788febf0c","0bba2cdbd85343b98e78137868a90165","a48e5d684a014707b299cd9aba0b7911","9216351abff44cbaadd1c8d42a4e6716","6c40d5586b25492d8387ccf7e4b4bb68","67cf63ea7b3b452999fb6580dc57becd","ed16c9df18684de5916b6a46694f80e6","c44692fc23764a37a5cf18b120fd08d6","3fe3616d0afd4d57badcdffa5bb12614","1c9064f5d29b43ed86f05892b6779f84","dfe5a3e7a326474da0606ed8c3d5aa94","766eadada0a54c438bfe32a490b0a00f","7e332dbe81d347f7a786ef5325008025","07dbde5be1594680a2e99a04bfdbce9e","93093fe9d7ba40afa9471f719f69453f","a623a68db8b64371843d166b472dced7","6ac88bd75eb04b97bcb9537103b1305b","379a39cbfd674ab09bc5d3897c73f2dd","21fbffaf198e4c00be89fa97a4c3758f","2c8d285a7792431ba313aac610ee2bfa","5063865006054ed4870eae5816c68061","a2a30e3705cb4ddba37b5010391de25a","3bfa9c182a6a4579a6beacbbe5f9cf4b","cd4ebbf695054bbbbe7486ae1d2403f9","c6a4fc9eb31f491e9fe378d9d5a66a08","e12624339d6d4035ab0bd999be936079","2523d92959024a3bb627ba87a8ca8d48","52a55d7f17c54134af4f9e897ed2ae36","6a6a55847e52433b9f5882bfc312d23e","f2670f6204ef4b1fb92c860d67800fb4","ab011dc5ea9b494982b8035d90040154"]},"id":"tTjqSHp8IjOp","executionInfo":{"status":"ok","timestamp":1619844326846,"user_tz":-480,"elapsed":52752,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}},"outputId":"06a576eb-2f25-40e5-bd99-87f1fd381607"},"source":["DATASET = 'imdb'\n","tokenizer = RobertaTokenizer.from_pretrained(\"allenai/reviews_roberta_base\")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"142b984e91784e82bfbae19e844f8261","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898822.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"40e0956ec9cb48eaa6c7a06aca6ba6bf","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c44692fc23764a37a5cf18b120fd08d6","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2.0, style=ProgressStyle(description_wi…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a623a68db8b64371843d166b472dced7","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=150.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cd4ebbf695054bbbbe7486ae1d2403f9","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=185.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RoTj34hLH6Ui","executionInfo":{"status":"ok","timestamp":1619844398800,"user_tz":-480,"elapsed":124700,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}},"outputId":"4fdd8bde-cec0-4299-c60b-ef7c903ff92e"},"source":["print(tokenizer.bos_token_id, tokenizer.bos_token, tokenizer.eos_token_id, tokenizer.eos_token)\n","MAX_SEQUENCE_LENGTH = 512\n","\n","\n","def load_and_tokenize(url, label2id={}, count_label = 0, tokenizer=tokenizer):\n","  # tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n","  block_size=512\n","  dataframe = []\n","  with urllib.request.urlopen(url) as f:\n","    for line in f:\n","      doc = json.loads(line.decode('utf-8'))['text']\n","      tokenized_text = tokenizer(doc, max_length=MAX_SEQUENCE_LENGTH, truncation=True, padding=\"max_length\")\n","      label = json.loads(line.decode('utf-8'))['label']\n","      \n","      if label not in label2id:\n","        label2id[label] = count_label\n","        count_label +=1\n","      tokenized_text['labels'] = torch.tensor(label2id[label])\n","      tokenized_text['input_ids'] = torch.tensor(tokenized_text['input_ids'])\n","      tokenized_text['attention_mask'] = torch.tensor(tokenized_text['attention_mask'])\n","      dataframe.append(tokenized_text)\n","  return dataframe, count_label, label2id\n","\n","train,count_label, label2id = load_and_tokenize(\"https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/\"+DATASET+\"/train.jsonl\", tokenizer=tokenizer)\n","dev,count_label,label2id = load_and_tokenize(\"https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/\"+DATASET+\"/dev.jsonl\",label2id,  count_label, tokenizer=tokenizer)\n","test,count_label,label2id = load_and_tokenize(\"https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/\"+DATASET+\"/test.jsonl\",label2id,  count_label, tokenizer=tokenizer)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0 <s> 2 </s>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ng0MCo9NH6XJ"},"source":["# config"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FKy95v85v3A4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619844398804,"user_tz":-480,"elapsed":124696,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}},"outputId":"b98712c9-9445-412c-c8a4-ffc2912ba479"},"source":["train[0]\n","print(len(train))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["20000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hTNu7bBNUJ7S"},"source":["Folder to save results"]},{"cell_type":"code","metadata":{"id":"U86TlZD8UJ7X"},"source":["RESULTS_DIR = f\"\"\"/content/drive/My Drive/DL_Project/results/imdb/No Adapter/\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JAeAUGarJxb6"},"source":["General packages and functions"]},{"cell_type":"code","metadata":{"id":"LUAcaKKFJGeX"},"source":["from transformers import TrainingArguments, Trainer, EvalPrediction\n","def compute_accuracy(p: EvalPrediction):\n","    labels = p.label_ids\n","    preds = np.argmax(p.predictions, axis=1)\n","    acc = accuracy_score(labels, preds)\n","    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n","    return {\n","        'accuracy': acc,\n","        'f1': f1,\n","        'precision': precision,\n","        'recall': recall\n","    }\n","\n","from transformers import AdapterType, AdapterConfig, HoulsbyConfig, PfeifferConfig"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LXIo9sQ2M43p"},"source":["def run_model(hyperparams_dict, model_name=\"roberta-base\",task_name=\"myown\",adapter_name=None,adapter_config=None,seed=999):\n","    global model\n","    config = RobertaConfig.from_pretrained(\n","        model_name,\n","        num_labels=len(label2id),\n","    )\n","    model = RobertaModelWithHeads.from_pretrained(\n","        model_name,\n","        config=config,\n","    )\n","\n","    if torch.cuda.is_available():\n","      model = model.to(\"cuda\")\n","    id2label= {v: k for k, v in label2id.items()}\n","    for param in model.base_model.parameters():\n","      param.requires_grad = False\n","\n","    # Add a matching classification head\n","    model.add_classification_head(\n","        task_name,\n","        num_labels=len(label2id),\n","        id2label=id2label,\n","        layers=2\n","      )\n","      \n","    '''\n","    if adapter_name:\n","      # add a new adapter\n","      if adapter_config:\n","        model.add_adapter(\n","            task_name,\n","            ##### remove AdapterType argument for v2 #####\n","            #AdapterType.text_task,\n","            config=adapter_config\n","        )\n","      else:\n","        model.add_adapter(\n","            task_name,\n","            ##### remove AdapterType argument for v2 #####\n","            #AdapterType.text_task \n","        )\n","      # Enable adapter training\n","      model.train_adapter([task_name])\n","      '''\n","\n","    # train, dev, test = get_datasets(tokenizer)\n","    training_args = TrainingArguments(\n","        learning_rate=hyperparams_dict['learning_rate'],\n","        num_train_epochs=hyperparams_dict['num_train_epochs'],\n","        per_device_train_batch_size=hyperparams_dict['per_device_train_batch_size'],\n","        per_device_eval_batch_size=hyperparams_dict['per_device_eval_batch_size'],\n","        logging_steps=hyperparams_dict['logging_steps'],\n","        save_steps=hyperparams_dict['save_steps'],\n","        output_dir='./models/'+task_name,\n","        overwrite_output_dir=True,\n","        do_train=True,\n","        do_eval=True,\n","        do_predict=True,\n","        evaluation_strategy='steps', # use evaluation_strategy='epoch' for v2, evaluation_strategy='step' for large dataset\n","        # The next line is important to ensure the dataset labels are properly passed to the model\n","        remove_unused_columns=False,\n","        load_best_model_at_end=True,\n","        metric_for_best_model=\"loss\",\n","        greater_is_better=False,\n","        seed=int(seed)\n","    )\n","\n","    # tensor_board = TensorBoardCallback()\n","    ##### Early Stopping #####\n","    es = EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.0)\n","    if adapter_name:\n","      trainer = Trainer(\n","          model=model,\n","          args=training_args,\n","          train_dataset=train,\n","          eval_dataset=dev,\n","          compute_metrics=compute_accuracy,\n","          callbacks=[es],\n","          adapter_names=[adapter_name]   \n","      )\n","    else:\n","      trainer = Trainer(\n","          model=model,\n","          args=training_args,\n","          train_dataset=train,\n","          eval_dataset=dev,\n","          callbacks=[es],\n","          compute_metrics=compute_accuracy\n","      )\n","    trainer.train()\n","\n","    ##### Explicitly set active adapter to pass it in model forward pass,             #####\n","    ##### otherwise the previous setting adapter_names=[adapter_name] not work for v2 #####\n","    #if adapter_name:\n","    #  trainer.model.set_active_adapters(adapter_name)\n","\n","    _, _, metrics = trainer.predict(dev)\n","    metrics['seed'] = seed\n","    dev_results.append(pd.DataFrame.from_dict(metrics, orient='index').T)\n","\n","    metrics['seed'] = seed\n","    _, _, metrics = trainer.predict(test)\n","    test_results.append(pd.DataFrame.from_dict(metrics, orient='index').T)\n","    \n","    filepath = RESULTS_DIR + \"\"\"{}_{}_{}\"\"\".format(task_name,seed,timestamp.strftime(\"%Y-%m-%dT%H_%M_%S\"))\n","    filepath = filepath + '_' + str(hyperparams_dict['learning_rate']) \\\n","                + '_' + str(hyperparams_dict['num_train_epochs']) \\\n","                + '_' + str(hyperparams_dict['per_device_train_batch_size'] ) \\\n","                + '_' + str(hyperparams_dict['per_device_eval_batch_size']) \\\n","                + '_' + str(hyperparams_dict['logging_steps']) \\\n","                + '_' + str(hyperparams_dict['save_steps'])\n","    trainer.save_model(filepath)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CH189097M2Aq"},"source":["### Model: RoBERTa Base\n","### Task: Reviews\n","### Finetuning: Standard with classification head\n","### Adapter: None (None /Custom /Default / Houlsby / Pfeiffer)"]},{"cell_type":"code","metadata":{"id":"o-WVVlNqM2Aq"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4lqaOie3M2Aq"},"source":["# MODEL_NAME = \"allenai/cs_roberta_base\"\n","MODEL_NAME = \"allenai/reviews_roberta_base\"\n","TASK_NAME = \"imdb_no_adapter_DAPT\" # cit_intent_base_myownadapter / cit_intent_base_pfieffer\n","ADAPTER_NAME = None # None pfieffer / cit_intent_base_finetune\n","\n","\n","ADAPTER_CONFIG = PfeifferConfig() # leave ADAPTER_CONFIG as None to default adapter\n","\n","# ADAPTER_CONFIG = AdapterConfig.load( # comment out if using default adapter\n","#     # adapter_args.adapter_config,\n","#     # non_linearity=adapter_args.adapter_non_linearity,\n","#     # reduction_factor=adapter_args.adapter_reduction_factor,\n","#     ADAPTER_NAME, \n","#     # non_linearity=adapter_args.adapter_non_linearity,\n","#     reduction_factor=12\n","# )\n","\n","# hyperparameters search\n","hyperparameters_dict = {'learning_rate':2e-5,'num_train_epochs':10,'per_device_train_batch_size':16,'per_device_eval_batch_size':16,'logging_steps':1000,'save_steps':1000} # hyperparameters for standard finetuning\n","'''\n","HYPERPARAMETERS_SEARCH = [{'learning_rate':1e-4,'num_train_epochs':10,'per_device_train_batch_size':16,'per_device_eval_batch_size':16,'logging_steps':1000,'save_steps':1000},\n","                          {'learning_rate':8e-5,'num_train_epochs':10,'per_device_train_batch_size':16,'per_device_eval_batch_size':16,'logging_steps':1000,'save_steps':1000},\n","                          {'learning_rate':2e-5,'num_train_epochs':10,'per_device_train_batch_size':16,'per_device_eval_batch_size':16,'logging_steps':1000,'save_steps':1000},\n","                          {'learning_rate':1e-4,'num_train_epochs':10,'per_device_train_batch_size':32,'per_device_eval_batch_size':32,'logging_steps':1000,'save_steps':1000},\n","                          {'learning_rate':8e-5,'num_train_epochs':10,'per_device_train_batch_size':32,'per_device_eval_batch_size':32,'logging_steps':1000,'save_steps':1000},\n","                          {'learning_rate':2e-5,'num_train_epochs':10,'per_device_train_batch_size':32,'per_device_eval_batch_size':32,'logging_steps':1000,'save_steps':1000},\n","                          ]\n","'''\n","HYPERPARAMETERS_SEARCH = [ {'learning_rate':2e-5,'num_train_epochs':10,'per_device_train_batch_size':16,'per_device_eval_batch_size':16,'logging_steps':1000,'save_steps':1000}]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u52XtNy1M2Aq","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1619861635696,"user_tz":-480,"elapsed":16741247,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}},"outputId":"7bdaba51-47e4-4cc3-e3de-7fb7e6bd4c49"},"source":["\n","\n","from datetime import datetime, timedelta\n","timestamp = datetime.today() + timedelta(hours=8)\n","tokenizer = RobertaTokenizer.from_pretrained(MODEL_NAME)\n","print(tokenizer.bos_token_id, tokenizer.bos_token, tokenizer.eos_token_id, tokenizer.eos_token)\n","\n","seeds = [42, 1, 2]\n","dev_results = []\n","test_results = []\n","print('seeds:', seeds)\n","\n","if ADAPTER_NAME:\n","    # if using adapter, loop by HYPERPARAMETERS_SEARCH defined above\n","    for hyperparameters_dict in HYPERPARAMETERS_SEARCH:\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        print(hyperparameters_dict)\n","        run_model(hyperparameters_dict, model_name=MODEL_NAME,task_name=TASK_NAME,adapter_name=ADAPTER_NAME,adapter_config=ADAPTER_CONFIG)\n","else: # if not using adapter, assume standard finetuning and loop by seeds\n","    for seed in seeds:\n","        print(type(int(seed)))\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        print(hyperparameters_dict)\n","        run_model(hyperparameters_dict, model_name=MODEL_NAME,task_name=TASK_NAME,adapter_name=ADAPTER_NAME,adapter_config=ADAPTER_CONFIG, seed=seed)\n","\n","dev_df = pd.concat(dev_results)\n","test_df = pd.concat(test_results)\n","\n","\n","# UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior._warn_prf(average, modifier, msg_start, len(result))\n","## some labels in y_test don't appear in y_pred. "],"execution_count":null,"outputs":[{"output_type":"stream","text":["0 <s> 2 </s>\n","seeds: [42, 1, 2]\n","<class 'int'>\n","{'learning_rate': 1e-05, 'num_train_epochs': 10, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 16, 'logging_steps': 1000, 'save_steps': 1000}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at allenai/reviews_roberta_base were not used when initializing RobertaModelWithHeads: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at allenai/reviews_roberta_base and are newly initialized: ['roberta.embeddings.position_ids']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='12500' max='12500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [12500/12500 1:23:51, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Runtime</th>\n","      <th>Samples Per Second</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.632600</td>\n","      <td>0.589917</td>\n","      <td>0.843400</td>\n","      <td>0.843282</td>\n","      <td>0.844434</td>\n","      <td>0.843400</td>\n","      <td>89.305000</td>\n","      <td>55.988000</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.531400</td>\n","      <td>0.500854</td>\n","      <td>0.851600</td>\n","      <td>0.851523</td>\n","      <td>0.852333</td>\n","      <td>0.851600</td>\n","      <td>89.336200</td>\n","      <td>55.968000</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.461300</td>\n","      <td>0.438082</td>\n","      <td>0.858400</td>\n","      <td>0.858159</td>\n","      <td>0.860850</td>\n","      <td>0.858400</td>\n","      <td>89.327400</td>\n","      <td>55.974000</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.415800</td>\n","      <td>0.392993</td>\n","      <td>0.868400</td>\n","      <td>0.868314</td>\n","      <td>0.869368</td>\n","      <td>0.868400</td>\n","      <td>89.382400</td>\n","      <td>55.939000</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.385700</td>\n","      <td>0.362959</td>\n","      <td>0.873000</td>\n","      <td>0.872994</td>\n","      <td>0.873073</td>\n","      <td>0.873000</td>\n","      <td>89.343100</td>\n","      <td>55.964000</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.363600</td>\n","      <td>0.344320</td>\n","      <td>0.876400</td>\n","      <td>0.876276</td>\n","      <td>0.877909</td>\n","      <td>0.876400</td>\n","      <td>89.385800</td>\n","      <td>55.937000</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.353300</td>\n","      <td>0.330761</td>\n","      <td>0.877800</td>\n","      <td>0.877660</td>\n","      <td>0.879534</td>\n","      <td>0.877800</td>\n","      <td>89.406200</td>\n","      <td>55.925000</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>0.345100</td>\n","      <td>0.319687</td>\n","      <td>0.880400</td>\n","      <td>0.880319</td>\n","      <td>0.881431</td>\n","      <td>0.880400</td>\n","      <td>89.378200</td>\n","      <td>55.942000</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>0.336900</td>\n","      <td>0.313558</td>\n","      <td>0.881600</td>\n","      <td>0.881479</td>\n","      <td>0.883169</td>\n","      <td>0.881600</td>\n","      <td>89.417800</td>\n","      <td>55.917000</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>0.336300</td>\n","      <td>0.307106</td>\n","      <td>0.886000</td>\n","      <td>0.885963</td>\n","      <td>0.886501</td>\n","      <td>0.886000</td>\n","      <td>89.416900</td>\n","      <td>55.918000</td>\n","    </tr>\n","    <tr>\n","      <td>11000</td>\n","      <td>0.332500</td>\n","      <td>0.304674</td>\n","      <td>0.885200</td>\n","      <td>0.885140</td>\n","      <td>0.886003</td>\n","      <td>0.885200</td>\n","      <td>89.388700</td>\n","      <td>55.936000</td>\n","    </tr>\n","    <tr>\n","      <td>12000</td>\n","      <td>0.332500</td>\n","      <td>0.303475</td>\n","      <td>0.885600</td>\n","      <td>0.885534</td>\n","      <td>0.886490</td>\n","      <td>0.885600</td>\n","      <td>89.361700</td>\n","      <td>55.952000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='1876' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [313/313 08:56]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["<class 'int'>\n","{'learning_rate': 1e-05, 'num_train_epochs': 10, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 16, 'logging_steps': 1000, 'save_steps': 1000}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at allenai/reviews_roberta_base were not used when initializing RobertaModelWithHeads: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at allenai/reviews_roberta_base and are newly initialized: ['roberta.embeddings.position_ids']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='12500' max='12500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [12500/12500 1:23:54, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Runtime</th>\n","      <th>Samples Per Second</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.637600</td>\n","      <td>0.595019</td>\n","      <td>0.842000</td>\n","      <td>0.841993</td>\n","      <td>0.842063</td>\n","      <td>0.842000</td>\n","      <td>89.322100</td>\n","      <td>55.977000</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.539600</td>\n","      <td>0.508041</td>\n","      <td>0.853600</td>\n","      <td>0.853570</td>\n","      <td>0.853894</td>\n","      <td>0.853600</td>\n","      <td>89.346900</td>\n","      <td>55.962000</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.467200</td>\n","      <td>0.443554</td>\n","      <td>0.859800</td>\n","      <td>0.859658</td>\n","      <td>0.861261</td>\n","      <td>0.859800</td>\n","      <td>89.334700</td>\n","      <td>55.969000</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.419100</td>\n","      <td>0.398844</td>\n","      <td>0.867200</td>\n","      <td>0.867050</td>\n","      <td>0.868866</td>\n","      <td>0.867200</td>\n","      <td>89.376900</td>\n","      <td>55.943000</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.388000</td>\n","      <td>0.367941</td>\n","      <td>0.874600</td>\n","      <td>0.874516</td>\n","      <td>0.875600</td>\n","      <td>0.874600</td>\n","      <td>89.409800</td>\n","      <td>55.922000</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.369500</td>\n","      <td>0.346684</td>\n","      <td>0.878600</td>\n","      <td>0.878554</td>\n","      <td>0.879171</td>\n","      <td>0.878600</td>\n","      <td>89.342200</td>\n","      <td>55.965000</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.355600</td>\n","      <td>0.334677</td>\n","      <td>0.877400</td>\n","      <td>0.877221</td>\n","      <td>0.879616</td>\n","      <td>0.877400</td>\n","      <td>89.367800</td>\n","      <td>55.949000</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>0.347700</td>\n","      <td>0.324733</td>\n","      <td>0.878400</td>\n","      <td>0.878242</td>\n","      <td>0.880372</td>\n","      <td>0.878400</td>\n","      <td>89.376200</td>\n","      <td>55.943000</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>0.343400</td>\n","      <td>0.315468</td>\n","      <td>0.882400</td>\n","      <td>0.882343</td>\n","      <td>0.883142</td>\n","      <td>0.882400</td>\n","      <td>89.338300</td>\n","      <td>55.967000</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>0.335800</td>\n","      <td>0.311318</td>\n","      <td>0.883400</td>\n","      <td>0.883315</td>\n","      <td>0.884521</td>\n","      <td>0.883400</td>\n","      <td>89.365900</td>\n","      <td>55.950000</td>\n","    </tr>\n","    <tr>\n","      <td>11000</td>\n","      <td>0.338900</td>\n","      <td>0.309137</td>\n","      <td>0.884200</td>\n","      <td>0.884083</td>\n","      <td>0.885760</td>\n","      <td>0.884200</td>\n","      <td>89.385500</td>\n","      <td>55.937000</td>\n","    </tr>\n","    <tr>\n","      <td>12000</td>\n","      <td>0.337900</td>\n","      <td>0.307476</td>\n","      <td>0.884000</td>\n","      <td>0.883893</td>\n","      <td>0.885425</td>\n","      <td>0.884000</td>\n","      <td>89.373600</td>\n","      <td>55.945000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='1876' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [313/313 08:56]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["<class 'int'>\n","{'learning_rate': 1e-05, 'num_train_epochs': 10, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 16, 'logging_steps': 1000, 'save_steps': 1000}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at allenai/reviews_roberta_base were not used when initializing RobertaModelWithHeads: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at allenai/reviews_roberta_base and are newly initialized: ['roberta.embeddings.position_ids']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='12500' max='12500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [12500/12500 1:23:49, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Runtime</th>\n","      <th>Samples Per Second</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.637400</td>\n","      <td>0.594707</td>\n","      <td>0.839200</td>\n","      <td>0.839138</td>\n","      <td>0.839722</td>\n","      <td>0.839200</td>\n","      <td>89.384100</td>\n","      <td>55.938000</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.538000</td>\n","      <td>0.508357</td>\n","      <td>0.850200</td>\n","      <td>0.850170</td>\n","      <td>0.850483</td>\n","      <td>0.850200</td>\n","      <td>89.346600</td>\n","      <td>55.962000</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.466500</td>\n","      <td>0.442046</td>\n","      <td>0.860800</td>\n","      <td>0.860781</td>\n","      <td>0.860994</td>\n","      <td>0.860800</td>\n","      <td>89.341700</td>\n","      <td>55.965000</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.420100</td>\n","      <td>0.398694</td>\n","      <td>0.866200</td>\n","      <td>0.866017</td>\n","      <td>0.868216</td>\n","      <td>0.866200</td>\n","      <td>89.370100</td>\n","      <td>55.947000</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.388900</td>\n","      <td>0.366518</td>\n","      <td>0.874600</td>\n","      <td>0.874558</td>\n","      <td>0.875097</td>\n","      <td>0.874600</td>\n","      <td>89.390200</td>\n","      <td>55.935000</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.374600</td>\n","      <td>0.348987</td>\n","      <td>0.873000</td>\n","      <td>0.872782</td>\n","      <td>0.875575</td>\n","      <td>0.873000</td>\n","      <td>89.389700</td>\n","      <td>55.935000</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.356300</td>\n","      <td>0.333317</td>\n","      <td>0.878400</td>\n","      <td>0.878282</td>\n","      <td>0.879879</td>\n","      <td>0.878400</td>\n","      <td>89.413000</td>\n","      <td>55.920000</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>0.355800</td>\n","      <td>0.322560</td>\n","      <td>0.881200</td>\n","      <td>0.881112</td>\n","      <td>0.882331</td>\n","      <td>0.881200</td>\n","      <td>89.384700</td>\n","      <td>55.938000</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>0.345700</td>\n","      <td>0.315962</td>\n","      <td>0.883400</td>\n","      <td>0.883302</td>\n","      <td>0.884694</td>\n","      <td>0.883400</td>\n","      <td>89.351900</td>\n","      <td>55.959000</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>0.332300</td>\n","      <td>0.310988</td>\n","      <td>0.884200</td>\n","      <td>0.884100</td>\n","      <td>0.885533</td>\n","      <td>0.884200</td>\n","      <td>89.336100</td>\n","      <td>55.968000</td>\n","    </tr>\n","    <tr>\n","      <td>11000</td>\n","      <td>0.335400</td>\n","      <td>0.308079</td>\n","      <td>0.884600</td>\n","      <td>0.884492</td>\n","      <td>0.886046</td>\n","      <td>0.884600</td>\n","      <td>89.262300</td>\n","      <td>56.015000</td>\n","    </tr>\n","    <tr>\n","      <td>12000</td>\n","      <td>0.329100</td>\n","      <td>0.306034</td>\n","      <td>0.886800</td>\n","      <td>0.886721</td>\n","      <td>0.887881</td>\n","      <td>0.886800</td>\n","      <td>89.295100</td>\n","      <td>55.994000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='1876' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [313/313 08:55]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"g5yMbjcAM2Ar","colab":{"base_uri":"https://localhost:8080/","height":832},"executionInfo":{"status":"ok","timestamp":1619861636175,"user_tz":-480,"elapsed":16564116,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}},"outputId":"2c8beaff-7b79-46a7-d8e1-90c1865314ab"},"source":["display(dev_df)\n","display(dev_df.describe())\n","\n","display(test_df)\n","display(test_df.describe())"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>test_loss</th>\n","      <th>test_accuracy</th>\n","      <th>test_f1</th>\n","      <th>test_precision</th>\n","      <th>test_recall</th>\n","      <th>test_runtime</th>\n","      <th>test_samples_per_second</th>\n","      <th>test_mem_cpu_alloc_delta</th>\n","      <th>test_mem_gpu_alloc_delta</th>\n","      <th>test_mem_cpu_peaked_delta</th>\n","      <th>test_mem_gpu_peaked_delta</th>\n","      <th>seed</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.303475</td>\n","      <td>0.8856</td>\n","      <td>0.885534</td>\n","      <td>0.886490</td>\n","      <td>0.8856</td>\n","      <td>89.3986</td>\n","      <td>55.929</td>\n","      <td>233472.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>780461056.0</td>\n","      <td>42.0</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>0.307476</td>\n","      <td>0.8840</td>\n","      <td>0.883893</td>\n","      <td>0.885425</td>\n","      <td>0.8840</td>\n","      <td>89.4289</td>\n","      <td>55.910</td>\n","      <td>212992.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>780454400.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>0.306034</td>\n","      <td>0.8868</td>\n","      <td>0.886721</td>\n","      <td>0.887881</td>\n","      <td>0.8868</td>\n","      <td>89.3536</td>\n","      <td>55.957</td>\n","      <td>-98304.0</td>\n","      <td>-132096.0</td>\n","      <td>241664.0</td>\n","      <td>780449280.0</td>\n","      <td>2.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   test_loss  test_accuracy  ...  test_mem_gpu_peaked_delta  seed\n","0   0.303475         0.8856  ...                780461056.0  42.0\n","0   0.307476         0.8840  ...                780454400.0   1.0\n","0   0.306034         0.8868  ...                780449280.0   2.0\n","\n","[3 rows x 12 columns]"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>test_loss</th>\n","      <th>test_accuracy</th>\n","      <th>test_f1</th>\n","      <th>test_precision</th>\n","      <th>test_recall</th>\n","      <th>test_runtime</th>\n","      <th>test_samples_per_second</th>\n","      <th>test_mem_cpu_alloc_delta</th>\n","      <th>test_mem_gpu_alloc_delta</th>\n","      <th>test_mem_cpu_peaked_delta</th>\n","      <th>test_mem_gpu_peaked_delta</th>\n","      <th>seed</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000e+00</td>\n","      <td>3.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.305662</td>\n","      <td>0.885467</td>\n","      <td>0.885383</td>\n","      <td>0.886599</td>\n","      <td>0.885467</td>\n","      <td>89.393700</td>\n","      <td>55.932000</td>\n","      <td>116053.333333</td>\n","      <td>-44032.000000</td>\n","      <td>80554.666667</td>\n","      <td>7.804549e+08</td>\n","      <td>15.000000</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.002026</td>\n","      <td>0.001405</td>\n","      <td>0.001420</td>\n","      <td>0.001232</td>\n","      <td>0.001405</td>\n","      <td>0.037888</td>\n","      <td>0.023643</td>\n","      <td>185921.105218</td>\n","      <td>76265.661159</td>\n","      <td>139524.775453</td>\n","      <td>5.904672e+03</td>\n","      <td>23.388031</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.303475</td>\n","      <td>0.884000</td>\n","      <td>0.883893</td>\n","      <td>0.885425</td>\n","      <td>0.884000</td>\n","      <td>89.353600</td>\n","      <td>55.910000</td>\n","      <td>-98304.000000</td>\n","      <td>-132096.000000</td>\n","      <td>0.000000</td>\n","      <td>7.804493e+08</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.304755</td>\n","      <td>0.884800</td>\n","      <td>0.884713</td>\n","      <td>0.885958</td>\n","      <td>0.884800</td>\n","      <td>89.376100</td>\n","      <td>55.919500</td>\n","      <td>57344.000000</td>\n","      <td>-66048.000000</td>\n","      <td>0.000000</td>\n","      <td>7.804518e+08</td>\n","      <td>1.500000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.306034</td>\n","      <td>0.885600</td>\n","      <td>0.885534</td>\n","      <td>0.886490</td>\n","      <td>0.885600</td>\n","      <td>89.398600</td>\n","      <td>55.929000</td>\n","      <td>212992.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>7.804544e+08</td>\n","      <td>2.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.306755</td>\n","      <td>0.886200</td>\n","      <td>0.886128</td>\n","      <td>0.887186</td>\n","      <td>0.886200</td>\n","      <td>89.413750</td>\n","      <td>55.943000</td>\n","      <td>223232.000000</td>\n","      <td>0.000000</td>\n","      <td>120832.000000</td>\n","      <td>7.804577e+08</td>\n","      <td>22.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>0.307476</td>\n","      <td>0.886800</td>\n","      <td>0.886721</td>\n","      <td>0.887881</td>\n","      <td>0.886800</td>\n","      <td>89.428900</td>\n","      <td>55.957000</td>\n","      <td>233472.000000</td>\n","      <td>0.000000</td>\n","      <td>241664.000000</td>\n","      <td>7.804611e+08</td>\n","      <td>42.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       test_loss  test_accuracy  ...  test_mem_gpu_peaked_delta       seed\n","count   3.000000       3.000000  ...               3.000000e+00   3.000000\n","mean    0.305662       0.885467  ...               7.804549e+08  15.000000\n","std     0.002026       0.001405  ...               5.904672e+03  23.388031\n","min     0.303475       0.884000  ...               7.804493e+08   1.000000\n","25%     0.304755       0.884800  ...               7.804518e+08   1.500000\n","50%     0.306034       0.885600  ...               7.804544e+08   2.000000\n","75%     0.306755       0.886200  ...               7.804577e+08  22.000000\n","max     0.307476       0.886800  ...               7.804611e+08  42.000000\n","\n","[8 rows x 12 columns]"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>test_loss</th>\n","      <th>test_accuracy</th>\n","      <th>test_f1</th>\n","      <th>test_precision</th>\n","      <th>test_recall</th>\n","      <th>test_runtime</th>\n","      <th>test_samples_per_second</th>\n","      <th>test_mem_cpu_alloc_delta</th>\n","      <th>test_mem_gpu_alloc_delta</th>\n","      <th>test_mem_cpu_peaked_delta</th>\n","      <th>test_mem_gpu_peaked_delta</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.297756</td>\n","      <td>0.88944</td>\n","      <td>0.889383</td>\n","      <td>0.890246</td>\n","      <td>0.88944</td>\n","      <td>446.8168</td>\n","      <td>55.951</td>\n","      <td>385024.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.310641e+08</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>0.301382</td>\n","      <td>0.88744</td>\n","      <td>0.887347</td>\n","      <td>0.888723</td>\n","      <td>0.88744</td>\n","      <td>446.8985</td>\n","      <td>55.941</td>\n","      <td>806912.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.082685e+09</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>0.300027</td>\n","      <td>0.88876</td>\n","      <td>0.888691</td>\n","      <td>0.889728</td>\n","      <td>0.88876</td>\n","      <td>446.3323</td>\n","      <td>56.012</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>7.808604e+08</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   test_loss  ...  test_mem_gpu_peaked_delta\n","0   0.297756  ...               8.310641e+08\n","0   0.301382  ...               1.082685e+09\n","0   0.300027  ...               7.808604e+08\n","\n","[3 rows x 11 columns]"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>test_loss</th>\n","      <th>test_accuracy</th>\n","      <th>test_f1</th>\n","      <th>test_precision</th>\n","      <th>test_recall</th>\n","      <th>test_runtime</th>\n","      <th>test_samples_per_second</th>\n","      <th>test_mem_cpu_alloc_delta</th>\n","      <th>test_mem_gpu_alloc_delta</th>\n","      <th>test_mem_cpu_peaked_delta</th>\n","      <th>test_mem_gpu_peaked_delta</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.299722</td>\n","      <td>0.888547</td>\n","      <td>0.888474</td>\n","      <td>0.889565</td>\n","      <td>0.888547</td>\n","      <td>446.682533</td>\n","      <td>55.968000</td>\n","      <td>397312.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.982031e+08</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.001832</td>\n","      <td>0.001017</td>\n","      <td>0.001035</td>\n","      <td>0.000775</td>\n","      <td>0.001017</td>\n","      <td>0.306049</td>\n","      <td>0.038432</td>\n","      <td>403596.320776</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.617258e+08</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.297756</td>\n","      <td>0.887440</td>\n","      <td>0.887347</td>\n","      <td>0.888723</td>\n","      <td>0.887440</td>\n","      <td>446.332300</td>\n","      <td>55.941000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>7.808604e+08</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.298892</td>\n","      <td>0.888100</td>\n","      <td>0.888019</td>\n","      <td>0.889225</td>\n","      <td>0.888100</td>\n","      <td>446.574550</td>\n","      <td>55.946000</td>\n","      <td>192512.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.059622e+08</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.300027</td>\n","      <td>0.888760</td>\n","      <td>0.888691</td>\n","      <td>0.889728</td>\n","      <td>0.888760</td>\n","      <td>446.816800</td>\n","      <td>55.951000</td>\n","      <td>385024.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.310641e+08</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.300705</td>\n","      <td>0.889100</td>\n","      <td>0.889037</td>\n","      <td>0.889987</td>\n","      <td>0.889100</td>\n","      <td>446.857650</td>\n","      <td>55.981500</td>\n","      <td>595968.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>9.568745e+08</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>0.301382</td>\n","      <td>0.889440</td>\n","      <td>0.889383</td>\n","      <td>0.890246</td>\n","      <td>0.889440</td>\n","      <td>446.898500</td>\n","      <td>56.012000</td>\n","      <td>806912.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.082685e+09</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       test_loss  ...  test_mem_gpu_peaked_delta\n","count   3.000000  ...               3.000000e+00\n","mean    0.299722  ...               8.982031e+08\n","std     0.001832  ...               1.617258e+08\n","min     0.297756  ...               7.808604e+08\n","25%     0.298892  ...               8.059622e+08\n","50%     0.300027  ...               8.310641e+08\n","75%     0.300705  ...               9.568745e+08\n","max     0.301382  ...               1.082685e+09\n","\n","[8 rows x 11 columns]"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"0pHUcyA9gIfL"},"source":["Saving results"]},{"cell_type":"code","metadata":{"id":"pGyRffDBM3qH"},"source":["\n","filepath = RESULTS_DIR+TASK_NAME\n","\n","# save adapter + classifier\n","if ADAPTER_NAME:\n","  model.save_adapter(filepath, TASK_NAME)\n","model.save_head(filepath, TASK_NAME)\n","\n","# dev and test results + hyperparameters used. hyperparameters will be in the same order dev_ and test_ results are appended\n","dev_df.to_excel(filepath+'/dev_results.xlsx',index=False)\n","test_df.to_excel(filepath+'/test_results.xlsx',index=False)\n","if ADAPTER_NAME:\n","  with open(filepath+'/hyperparameters.py', 'w') as writefile:\n","      writefile.write(\"HYPERPARAMETERS_SEARCH = {}\".format(HYPERPARAMETERS_SEARCH))\n","else:\n","  with open(filepath+'/hyperparameters.py', 'w') as writefile:\n","      writefile.write(\"HYPERPARAMETERS_SEARCH = {}\".format(hyperparameters_dict))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dmgfsM3OM3wT"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"843wO0bteSmH"},"source":[""],"execution_count":null,"outputs":[]}]}