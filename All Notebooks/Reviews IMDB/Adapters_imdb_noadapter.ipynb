{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Adapters_imdb_noadapter.ipynb","provenance":[{"file_id":"1S2xY76CG2puXMlww-LB6vf51JhAcVvhf","timestamp":1619336370224},{"file_id":"1qDkodosI-REs-LqRomx0fyzmtIliDwi1","timestamp":1619334473343},{"file_id":"1jkthCAgVbiEwPYMJ2FQzHtrpiI71P7np","timestamp":1619324777840}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"lZj-G8LIXLpj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619845624070,"user_tz":-480,"elapsed":14702,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}},"outputId":"6a276144-5981-4388-9883-9d5f21df41f0"},"source":["# mount google drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","# log_dir='/content/gdrive/MyDrive/DL_Project/runs'\n","# !mkdir -p {log_dir}\n","# !mv ./runs/* {log_dir}"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D61LwET3WrOD","executionInfo":{"status":"ok","timestamp":1619845747866,"user_tz":-480,"elapsed":138493,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}},"outputId":"99358a8f-9cb2-4661-abbb-fcf2fb77f48b"},"source":["!pip install -U git+https://github.com/Adapter-Hub/adapter-transformers.git@v2\n","!pip install torch==1.7.1\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/Adapter-Hub/adapter-transformers.git@v2\n","  Cloning https://github.com/Adapter-Hub/adapter-transformers.git (to revision v2) to /tmp/pip-req-build-sls9kggz\n","  Running command git clone -q https://github.com/Adapter-Hub/adapter-transformers.git /tmp/pip-req-build-sls9kggz\n","  Running command git checkout -b v2 --track origin/v2\n","  Switched to a new branch 'v2'\n","  Branch 'v2' set up to track remote branch 'v2' from 'origin'.\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from adapter-transformers==2.0.0a1) (20.9)\n","Requirement already satisfied, skipping upgrade: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from adapter-transformers==2.0.0a1) (4.41.1)\n","Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from adapter-transformers==2.0.0a1) (2019.12.20)\n","Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from adapter-transformers==2.0.0a1) (2.23.0)\n","Requirement already satisfied, skipping upgrade: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from adapter-transformers==2.0.0a1) (1.19.5)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 7.7MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 35.6MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from adapter-transformers==2.0.0a1) (3.10.1)\n","Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.7/dist-packages (from adapter-transformers==2.0.0a1) (3.0.12)\n","Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->adapter-transformers==2.0.0a1) (2.4.7)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->adapter-transformers==2.0.0a1) (1.24.3)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->adapter-transformers==2.0.0a1) (3.0.4)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->adapter-transformers==2.0.0a1) (2020.12.5)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->adapter-transformers==2.0.0a1) (2.10)\n","Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->adapter-transformers==2.0.0a1) (1.0.1)\n","Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->adapter-transformers==2.0.0a1) (7.1.2)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->adapter-transformers==2.0.0a1) (1.15.0)\n","Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->adapter-transformers==2.0.0a1) (3.4.1)\n","Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->adapter-transformers==2.0.0a1) (3.7.4.3)\n","Building wheels for collected packages: adapter-transformers\n","  Building wheel for adapter-transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for adapter-transformers: filename=adapter_transformers-2.0.0a1-cp37-none-any.whl size=2097547 sha256=74b8da18eec32498eed5c4efb13818d95c372925387f6b0b77b442e11a49a1f9\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-iy810buw/wheels/11/c5/35/7017ef1a9923a73e9d8071801894534ab1fa662e38e23b78f1\n","Successfully built adapter-transformers\n","Installing collected packages: tokenizers, sacremoses, adapter-transformers\n","Successfully installed adapter-transformers-2.0.0a1 sacremoses-0.0.45 tokenizers-0.10.2\n","Collecting torch==1.7.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/5d/095ddddc91c8a769a68c791c019c5793f9c4456a688ddd235d6670924ecb/torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8MB)\n","\u001b[K     |████████████████████████████████| 776.8MB 25kB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1) (3.7.4.3)\n","\u001b[31mERROR: torchvision 0.9.1+cu101 has requirement torch==1.8.1, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n","Installing collected packages: torch\n","  Found existing installation: torch 1.8.1+cu101\n","    Uninstalling torch-1.8.1+cu101:\n","      Successfully uninstalled torch-1.8.1+cu101\n","Successfully installed torch-1.7.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DPpEKGrz_iNF","executionInfo":{"status":"ok","timestamp":1619845752262,"user_tz":-480,"elapsed":142885,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}},"outputId":"79c25599-9ac6-4b76-a003-502acb1a6240"},"source":["import json, gc\n","import urllib.request\n","import numpy as np\n","import pandas as pd\n","import torch\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Using device:', device)\n","\n","from transformers import (\n","    MODEL_WITH_LM_HEAD_MAPPING,\n","    WEIGHTS_NAME,\n","    AdamW,\n","    AutoConfig,\n","    AutoModelWithLMHead,\n","    AutoTokenizer,\n","    PreTrainedModel,\n","    PreTrainedTokenizer,\n","    get_linear_schedule_with_warmup,\n","    RobertaTokenizer\n",")\n","from transformers import RobertaForSequenceClassification, RobertaModelWithHeads, RobertaConfig\n","from transformers import TrainingArguments, Trainer, EvalPrediction\n","\n","from sklearn import metrics\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","\n","from transformers import EarlyStoppingCallback\n","from transformers.integrations import TensorBoardCallback\n","from tensorflow import summary\n","import tensorflow\n","%load_ext tensorboard\n","import datetime"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using device: cuda\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wwRHoyT1Kwyl"},"source":["Dataset and Tokenizers"]},{"cell_type":"code","metadata":{"id":"m4NX9BQHHtVA","executionInfo":{"status":"ok","timestamp":1619845752263,"user_tz":-480,"elapsed":142884,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}}},"source":[""],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"tTjqSHp8IjOp","executionInfo":{"status":"ok","timestamp":1619857882843,"user_tz":-480,"elapsed":2614,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}}},"source":["DATASET = 'imdb'\n","tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RoTj34hLH6Ui","executionInfo":{"status":"ok","timestamp":1619858319466,"user_tz":-480,"elapsed":437781,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}},"outputId":"52663013-42ab-4bdd-f453-985762136b46"},"source":["print(tokenizer.bos_token_id, tokenizer.bos_token, tokenizer.eos_token_id, tokenizer.eos_token)\n","MAX_SEQUENCE_LENGTH = 512\n","\n","\n","def load_and_tokenize(url, label2id={}, count_label = 0, tokenizer=tokenizer):\n","  # tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n","  block_size=512\n","  dataframe = []\n","  with urllib.request.urlopen(url) as f:\n","    for line in f:\n","      doc = json.loads(line.decode('utf-8'))['text']\n","      tokenized_text = tokenizer(doc, max_length=MAX_SEQUENCE_LENGTH, truncation=True, padding=\"max_length\")\n","      label = json.loads(line.decode('utf-8'))['label']\n","      \n","      if label not in label2id:\n","        label2id[label] = count_label\n","        count_label +=1\n","      tokenized_text['labels'] = torch.tensor(label2id[label])\n","      tokenized_text['input_ids'] = torch.tensor(tokenized_text['input_ids'])\n","      tokenized_text['attention_mask'] = torch.tensor(tokenized_text['attention_mask'])\n","      dataframe.append(tokenized_text)\n","  return dataframe, count_label, label2id\n","\n","train,count_label, label2id = load_and_tokenize(\"https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/\"+DATASET+\"/train.jsonl\", tokenizer=tokenizer)\n","dev,count_label,label2id = load_and_tokenize(\"https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/\"+DATASET+\"/dev.jsonl\",label2id,  count_label, tokenizer=tokenizer)\n","test,count_label,label2id = load_and_tokenize(\"https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/\"+DATASET+\"/test.jsonl\",label2id,  count_label, tokenizer=tokenizer)\n"],"execution_count":14,"outputs":[{"output_type":"stream","text":["0 <s> 2 </s>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ng0MCo9NH6XJ","executionInfo":{"status":"ok","timestamp":1619858319470,"user_tz":-480,"elapsed":435937,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}}},"source":["# config"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"FKy95v85v3A4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619858319471,"user_tz":-480,"elapsed":435415,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}},"outputId":"820bf7da-6bdf-47d6-bd28-2476b61985d6"},"source":["train[0]\n","print(len(train))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["20000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hTNu7bBNUJ7S"},"source":["Folder to save results"]},{"cell_type":"code","metadata":{"id":"U86TlZD8UJ7X","executionInfo":{"status":"ok","timestamp":1619858319471,"user_tz":-480,"elapsed":434759,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}}},"source":["RESULTS_DIR = f\"\"\"/content/drive/My Drive/DL_Project/results/No Adapter/\"\"\""],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JAeAUGarJxb6"},"source":["General packages and functions"]},{"cell_type":"code","metadata":{"id":"LUAcaKKFJGeX","executionInfo":{"status":"ok","timestamp":1619858319472,"user_tz":-480,"elapsed":434219,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}}},"source":["from transformers import TrainingArguments, Trainer, EvalPrediction\n","def compute_accuracy(p: EvalPrediction):\n","    labels = p.label_ids\n","    preds = np.argmax(p.predictions, axis=1)\n","    acc = accuracy_score(labels, preds)\n","    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n","    return {\n","        'accuracy': acc,\n","        'f1': f1,\n","        'precision': precision,\n","        'recall': recall\n","    }\n","\n","from transformers import AdapterType, AdapterConfig, HoulsbyConfig, PfeifferConfig"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"LXIo9sQ2M43p","executionInfo":{"status":"ok","timestamp":1619858319472,"user_tz":-480,"elapsed":432323,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}}},"source":["def run_model(hyperparams_dict, model_name=\"roberta-base\",task_name=\"myown\",adapter_name=None,adapter_config=None,seed=999):\n","    global model\n","    config = RobertaConfig.from_pretrained(\n","        model_name,\n","        num_labels=len(label2id),\n","    )\n","    model = RobertaModelWithHeads.from_pretrained(\n","        model_name,\n","        config=config,\n","    )\n","\n","    if torch.cuda.is_available():\n","      model = model.to(\"cuda\")\n","    id2label= {v: k for k, v in label2id.items()}\n","    for param in model.base_model.parameters():\n","      param.requires_grad = False\n","\n","    # Add a matching classification head\n","    model.add_classification_head(\n","        task_name,\n","        num_labels=len(label2id),\n","        id2label=id2label,\n","        layers=2\n","      )\n","      \n","    '''\n","    if adapter_name:\n","      # add a new adapter\n","      if adapter_config:\n","        model.add_adapter(\n","            task_name,\n","            ##### remove AdapterType argument for v2 #####\n","            #AdapterType.text_task,\n","            config=adapter_config\n","        )\n","      else:\n","        model.add_adapter(\n","            task_name,\n","            ##### remove AdapterType argument for v2 #####\n","            #AdapterType.text_task \n","        )\n","      # Enable adapter training\n","      model.train_adapter([task_name])\n","      '''\n","\n","    # train, dev, test = get_datasets(tokenizer)\n","    training_args = TrainingArguments(\n","        learning_rate=hyperparams_dict['learning_rate'],\n","        num_train_epochs=hyperparams_dict['num_train_epochs'],\n","        per_device_train_batch_size=hyperparams_dict['per_device_train_batch_size'],\n","        per_device_eval_batch_size=hyperparams_dict['per_device_eval_batch_size'],\n","        logging_steps=hyperparams_dict['logging_steps'],\n","        save_steps=hyperparams_dict['save_steps'],\n","        output_dir='./models/'+task_name,\n","        overwrite_output_dir=True,\n","        do_train=True,\n","        do_eval=True,\n","        do_predict=True,\n","        evaluation_strategy='steps', # use evaluation_strategy='epoch' for v2, evaluation_strategy='step' for large dataset\n","        # The next line is important to ensure the dataset labels are properly passed to the model\n","        remove_unused_columns=False,\n","        load_best_model_at_end=True,\n","        metric_for_best_model=\"loss\",\n","        greater_is_better=False,\n","        seed=int(seed)\n","    )\n","\n","    # tensor_board = TensorBoardCallback()\n","    ##### Early Stopping #####\n","    es = EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.0)\n","    if adapter_name:\n","      trainer = Trainer(\n","          model=model,\n","          args=training_args,\n","          train_dataset=train,\n","          eval_dataset=dev,\n","          compute_metrics=compute_accuracy,\n","          callbacks=[es],\n","          adapter_names=[adapter_name]   \n","      )\n","    else:\n","      trainer = Trainer(\n","          model=model,\n","          args=training_args,\n","          train_dataset=train,\n","          eval_dataset=dev,\n","          callbacks=[es],\n","          compute_metrics=compute_accuracy\n","      )\n","    trainer.train()\n","\n","    ##### Explicitly set active adapter to pass it in model forward pass,             #####\n","    ##### otherwise the previous setting adapter_names=[adapter_name] not work for v2 #####\n","    #if adapter_name:\n","    #  trainer.model.set_active_adapters(adapter_name)\n","\n","    _, _, metrics = trainer.predict(dev)\n","    metrics['seed'] = seed\n","    dev_results.append(pd.DataFrame.from_dict(metrics, orient='index').T)\n","\n","    metrics['seed'] = seed\n","    _, _, metrics = trainer.predict(test)\n","    test_results.append(pd.DataFrame.from_dict(metrics, orient='index').T)\n","    \n","    filepath = RESULTS_DIR + \"\"\"{}_{}_{}\"\"\".format(task_name,seed,timestamp.strftime(\"%Y-%m-%dT%H_%M_%S\"))\n","    filepath = filepath + '_' + str(hyperparams_dict['learning_rate']) \\\n","                + '_' + str(hyperparams_dict['num_train_epochs']) \\\n","                + '_' + str(hyperparams_dict['per_device_train_batch_size'] ) \\\n","                + '_' + str(hyperparams_dict['per_device_eval_batch_size']) \\\n","                + '_' + str(hyperparams_dict['logging_steps']) \\\n","                + '_' + str(hyperparams_dict['save_steps'])\n","    trainer.save_model(filepath)"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CH189097M2Aq"},"source":["### Model: RoBERTa Base\n","### Task: Reviews\n","### Finetuning: Standard with classification head\n","### Adapter: None (None /Custom /Default / Houlsby / Pfeiffer)"]},{"cell_type":"code","metadata":{"id":"o-WVVlNqM2Aq","executionInfo":{"status":"ok","timestamp":1619845967918,"user_tz":-480,"elapsed":358516,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}}},"source":[""],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"4lqaOie3M2Aq","executionInfo":{"status":"ok","timestamp":1619858320419,"user_tz":-480,"elapsed":927,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}}},"source":["# MODEL_NAME = \"allenai/cs_roberta_base\"\n","MODEL_NAME = \"roberta-base\"\n","TASK_NAME = \"imdb_no_adapter\" # cit_intent_base_myownadapter / cit_intent_base_pfieffer\n","ADAPTER_NAME = None # None pfieffer / cit_intent_base_finetune\n","\n","\n","ADAPTER_CONFIG = PfeifferConfig() # leave ADAPTER_CONFIG as None to default adapter\n","\n","# ADAPTER_CONFIG = AdapterConfig.load( # comment out if using default adapter\n","#     # adapter_args.adapter_config,\n","#     # non_linearity=adapter_args.adapter_non_linearity,\n","#     # reduction_factor=adapter_args.adapter_reduction_factor,\n","#     ADAPTER_NAME, \n","#     # non_linearity=adapter_args.adapter_non_linearity,\n","#     reduction_factor=12\n","# )\n","\n","# hyperparameters search\n","hyperparameters_dict = {'learning_rate':4e-5,'num_train_epochs':3,'per_device_train_batch_size':16,'per_device_eval_batch_size':16,'logging_steps':1000,'save_steps':1000} # hyperparameters for standard finetuning\n","'''\n","HYPERPARAMETERS_SEARCH = [{'learning_rate':1e-4,'num_train_epochs':10,'per_device_train_batch_size':16,'per_device_eval_batch_size':16,'logging_steps':1000,'save_steps':1000},\n","                          {'learning_rate':8e-5,'num_train_epochs':10,'per_device_train_batch_size':16,'per_device_eval_batch_size':16,'logging_steps':1000,'save_steps':1000},\n","                          {'learning_rate':2e-5,'num_train_epochs':10,'per_device_train_batch_size':16,'per_device_eval_batch_size':16,'logging_steps':1000,'save_steps':1000},\n","                          {'learning_rate':1e-4,'num_train_epochs':10,'per_device_train_batch_size':32,'per_device_eval_batch_size':32,'logging_steps':1000,'save_steps':1000},\n","                          {'learning_rate':8e-5,'num_train_epochs':10,'per_device_train_batch_size':32,'per_device_eval_batch_size':32,'logging_steps':1000,'save_steps':1000},\n","                          {'learning_rate':2e-5,'num_train_epochs':10,'per_device_train_batch_size':32,'per_device_eval_batch_size':32,'logging_steps':1000,'save_steps':1000},\n","                          ]\n","'''\n","HYPERPARAMETERS_SEARCH = [ {'learning_rate':4e-5,'num_train_epochs':3,'per_device_train_batch_size':16,'per_device_eval_batch_size':16,'logging_steps':1000,'save_steps':1000}]\n"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"u52XtNy1M2Aq","colab":{"base_uri":"https://localhost:8080/","height":928},"executionInfo":{"status":"ok","timestamp":1619864513040,"user_tz":-480,"elapsed":6193537,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}},"outputId":"9483f092-3d7c-422c-89b8-fe151e5f624c"},"source":["\n","\n","from datetime import datetime, timedelta\n","timestamp = datetime.today() + timedelta(hours=8)\n","tokenizer = RobertaTokenizer.from_pretrained(MODEL_NAME)\n","print(tokenizer.bos_token_id, tokenizer.bos_token, tokenizer.eos_token_id, tokenizer.eos_token)\n","\n","seeds = [42,1,2]\n","dev_results = []\n","test_results = []\n","print('seeds:', seeds)\n","\n","if ADAPTER_NAME:\n","    # if using adapter, loop by HYPERPARAMETERS_SEARCH defined above\n","    for hyperparameters_dict in HYPERPARAMETERS_SEARCH:\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        print(hyperparameters_dict)\n","        run_model(hyperparameters_dict, model_name=MODEL_NAME,task_name=TASK_NAME,adapter_name=ADAPTER_NAME,adapter_config=ADAPTER_CONFIG)\n","else: # if not using adapter, assume standard finetuning and loop by seeds\n","    for seed in seeds:\n","        print(type(int(seed)))\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        print(hyperparameters_dict)\n","        run_model(hyperparameters_dict, model_name=MODEL_NAME,task_name=TASK_NAME,adapter_name=ADAPTER_NAME,adapter_config=ADAPTER_CONFIG, seed=seed)\n","\n","dev_df = pd.concat(dev_results)\n","test_df = pd.concat(test_results)\n","\n","\n","# UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior._warn_prf(average, modifier, msg_start, len(result))\n","## some labels in y_test don't appear in y_pred. "],"execution_count":21,"outputs":[{"output_type":"stream","text":["0 <s> 2 </s>\n","seeds: [42, 1, 2]\n","<class 'int'>\n","{'learning_rate': 4e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 16, 'logging_steps': 1000, 'save_steps': 1000}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='3750' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3750/3750 24:57, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Runtime</th>\n","      <th>Samples Per Second</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.651300</td>\n","      <td>0.607851</td>\n","      <td>0.816200</td>\n","      <td>0.815115</td>\n","      <td>0.823800</td>\n","      <td>0.816200</td>\n","      <td>90.219100</td>\n","      <td>55.421000</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.567700</td>\n","      <td>0.528775</td>\n","      <td>0.836400</td>\n","      <td>0.836148</td>\n","      <td>0.838480</td>\n","      <td>0.836400</td>\n","      <td>90.200600</td>\n","      <td>55.432000</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.514700</td>\n","      <td>0.491787</td>\n","      <td>0.843000</td>\n","      <td>0.842681</td>\n","      <td>0.845801</td>\n","      <td>0.843000</td>\n","      <td>90.272300</td>\n","      <td>55.388000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='1876' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [313/313 09:02]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["<class 'int'>\n","{'learning_rate': 4e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 16, 'logging_steps': 1000, 'save_steps': 1000}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='3750' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3750/3750 24:59, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Runtime</th>\n","      <th>Samples Per Second</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.653000</td>\n","      <td>0.610958</td>\n","      <td>0.820600</td>\n","      <td>0.820110</td>\n","      <td>0.824133</td>\n","      <td>0.820600</td>\n","      <td>90.243700</td>\n","      <td>55.406000</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.570600</td>\n","      <td>0.533013</td>\n","      <td>0.831000</td>\n","      <td>0.830768</td>\n","      <td>0.832823</td>\n","      <td>0.831000</td>\n","      <td>90.273200</td>\n","      <td>55.387000</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.519900</td>\n","      <td>0.495098</td>\n","      <td>0.842400</td>\n","      <td>0.842250</td>\n","      <td>0.843704</td>\n","      <td>0.842400</td>\n","      <td>90.307500</td>\n","      <td>55.366000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='1876' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [313/313 09:02]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["<class 'int'>\n","{'learning_rate': 4e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 16, 'logging_steps': 1000, 'save_steps': 1000}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='3750' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3750/3750 24:59, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Runtime</th>\n","      <th>Samples Per Second</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.652600</td>\n","      <td>0.609655</td>\n","      <td>0.803400</td>\n","      <td>0.801787</td>\n","      <td>0.813606</td>\n","      <td>0.803400</td>\n","      <td>90.228900</td>\n","      <td>55.415000</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.570700</td>\n","      <td>0.533545</td>\n","      <td>0.836200</td>\n","      <td>0.836054</td>\n","      <td>0.837398</td>\n","      <td>0.836200</td>\n","      <td>90.293100</td>\n","      <td>55.375000</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.516500</td>\n","      <td>0.493100</td>\n","      <td>0.846200</td>\n","      <td>0.846199</td>\n","      <td>0.846212</td>\n","      <td>0.846200</td>\n","      <td>90.227700</td>\n","      <td>55.415000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='1876' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [313/313 09:02]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"g5yMbjcAM2Ar","colab":{"base_uri":"https://localhost:8080/","height":832},"executionInfo":{"status":"ok","timestamp":1619864513505,"user_tz":-480,"elapsed":6193995,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}},"outputId":"cae98512-77d3-49a6-b368-aa35401ab813"},"source":["display(dev_df)\n","display(dev_df.describe())\n","\n","display(test_df)\n","\n","display(test_df.describe())"],"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>test_loss</th>\n","      <th>test_accuracy</th>\n","      <th>test_f1</th>\n","      <th>test_precision</th>\n","      <th>test_recall</th>\n","      <th>test_runtime</th>\n","      <th>test_samples_per_second</th>\n","      <th>test_mem_cpu_alloc_delta</th>\n","      <th>test_mem_gpu_alloc_delta</th>\n","      <th>test_mem_cpu_peaked_delta</th>\n","      <th>test_mem_gpu_peaked_delta</th>\n","      <th>seed</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.491787</td>\n","      <td>0.8430</td>\n","      <td>0.842681</td>\n","      <td>0.845801</td>\n","      <td>0.8430</td>\n","      <td>90.2886</td>\n","      <td>55.378</td>\n","      <td>270336.0</td>\n","      <td>-132096.0</td>\n","      <td>0.0</td>\n","      <td>805622784.0</td>\n","      <td>42.0</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>0.495098</td>\n","      <td>0.8424</td>\n","      <td>0.842250</td>\n","      <td>0.843704</td>\n","      <td>0.8424</td>\n","      <td>90.3095</td>\n","      <td>55.365</td>\n","      <td>1261568.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>780443136.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>0.493100</td>\n","      <td>0.8462</td>\n","      <td>0.846199</td>\n","      <td>0.846212</td>\n","      <td>0.8462</td>\n","      <td>90.2652</td>\n","      <td>55.392</td>\n","      <td>286720.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>780420096.0</td>\n","      <td>2.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   test_loss  test_accuracy  ...  test_mem_gpu_peaked_delta  seed\n","0   0.491787         0.8430  ...                805622784.0  42.0\n","0   0.495098         0.8424  ...                780443136.0   1.0\n","0   0.493100         0.8462  ...                780420096.0   2.0\n","\n","[3 rows x 12 columns]"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>test_loss</th>\n","      <th>test_accuracy</th>\n","      <th>test_f1</th>\n","      <th>test_precision</th>\n","      <th>test_recall</th>\n","      <th>test_runtime</th>\n","      <th>test_samples_per_second</th>\n","      <th>test_mem_cpu_alloc_delta</th>\n","      <th>test_mem_gpu_alloc_delta</th>\n","      <th>test_mem_cpu_peaked_delta</th>\n","      <th>test_mem_gpu_peaked_delta</th>\n","      <th>seed</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000e+00</td>\n","      <td>3.000000</td>\n","      <td>3.0</td>\n","      <td>3.000000e+00</td>\n","      <td>3.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.493328</td>\n","      <td>0.843867</td>\n","      <td>0.843710</td>\n","      <td>0.845239</td>\n","      <td>0.843867</td>\n","      <td>90.287767</td>\n","      <td>55.378333</td>\n","      <td>6.062080e+05</td>\n","      <td>-44032.000000</td>\n","      <td>0.0</td>\n","      <td>7.888287e+08</td>\n","      <td>15.000000</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.001667</td>\n","      <td>0.002043</td>\n","      <td>0.002166</td>\n","      <td>0.001345</td>\n","      <td>0.002043</td>\n","      <td>0.022162</td>\n","      <td>0.013503</td>\n","      <td>5.676175e+05</td>\n","      <td>76265.661159</td>\n","      <td>0.0</td>\n","      <td>1.454413e+07</td>\n","      <td>23.388031</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.491787</td>\n","      <td>0.842400</td>\n","      <td>0.842250</td>\n","      <td>0.843704</td>\n","      <td>0.842400</td>\n","      <td>90.265200</td>\n","      <td>55.365000</td>\n","      <td>2.703360e+05</td>\n","      <td>-132096.000000</td>\n","      <td>0.0</td>\n","      <td>7.804201e+08</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.492443</td>\n","      <td>0.842700</td>\n","      <td>0.842466</td>\n","      <td>0.844753</td>\n","      <td>0.842700</td>\n","      <td>90.276900</td>\n","      <td>55.371500</td>\n","      <td>2.785280e+05</td>\n","      <td>-66048.000000</td>\n","      <td>0.0</td>\n","      <td>7.804316e+08</td>\n","      <td>1.500000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.493100</td>\n","      <td>0.843000</td>\n","      <td>0.842681</td>\n","      <td>0.845801</td>\n","      <td>0.843000</td>\n","      <td>90.288600</td>\n","      <td>55.378000</td>\n","      <td>2.867200e+05</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>7.804431e+08</td>\n","      <td>2.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.494099</td>\n","      <td>0.844600</td>\n","      <td>0.844440</td>\n","      <td>0.846007</td>\n","      <td>0.844600</td>\n","      <td>90.299050</td>\n","      <td>55.385000</td>\n","      <td>7.741440e+05</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>7.930330e+08</td>\n","      <td>22.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>0.495098</td>\n","      <td>0.846200</td>\n","      <td>0.846199</td>\n","      <td>0.846212</td>\n","      <td>0.846200</td>\n","      <td>90.309500</td>\n","      <td>55.392000</td>\n","      <td>1.261568e+06</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>8.056228e+08</td>\n","      <td>42.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       test_loss  test_accuracy  ...  test_mem_gpu_peaked_delta       seed\n","count   3.000000       3.000000  ...               3.000000e+00   3.000000\n","mean    0.493328       0.843867  ...               7.888287e+08  15.000000\n","std     0.001667       0.002043  ...               1.454413e+07  23.388031\n","min     0.491787       0.842400  ...               7.804201e+08   1.000000\n","25%     0.492443       0.842700  ...               7.804316e+08   1.500000\n","50%     0.493100       0.843000  ...               7.804431e+08   2.000000\n","75%     0.494099       0.844600  ...               7.930330e+08  22.000000\n","max     0.495098       0.846200  ...               8.056228e+08  42.000000\n","\n","[8 rows x 12 columns]"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>test_loss</th>\n","      <th>test_accuracy</th>\n","      <th>test_f1</th>\n","      <th>test_precision</th>\n","      <th>test_recall</th>\n","      <th>test_runtime</th>\n","      <th>test_samples_per_second</th>\n","      <th>test_mem_cpu_alloc_delta</th>\n","      <th>test_mem_gpu_alloc_delta</th>\n","      <th>test_mem_cpu_peaked_delta</th>\n","      <th>test_mem_gpu_peaked_delta</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.487325</td>\n","      <td>0.84660</td>\n","      <td>0.846323</td>\n","      <td>0.849115</td>\n","      <td>0.84660</td>\n","      <td>451.1690</td>\n","      <td>55.412</td>\n","      <td>-10715136.0</td>\n","      <td>0.0</td>\n","      <td>10715136.0</td>\n","      <td>7.808691e+08</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>0.491194</td>\n","      <td>0.84584</td>\n","      <td>0.845708</td>\n","      <td>0.847030</td>\n","      <td>0.84584</td>\n","      <td>451.1802</td>\n","      <td>55.410</td>\n","      <td>1462272.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.132996e+09</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>0.489327</td>\n","      <td>0.84432</td>\n","      <td>0.844320</td>\n","      <td>0.844323</td>\n","      <td>0.84432</td>\n","      <td>451.4747</td>\n","      <td>55.374</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>7.808691e+08</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   test_loss  ...  test_mem_gpu_peaked_delta\n","0   0.487325  ...               7.808691e+08\n","0   0.491194  ...               1.132996e+09\n","0   0.489327  ...               7.808691e+08\n","\n","[3 rows x 11 columns]"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>test_loss</th>\n","      <th>test_accuracy</th>\n","      <th>test_f1</th>\n","      <th>test_precision</th>\n","      <th>test_recall</th>\n","      <th>test_runtime</th>\n","      <th>test_samples_per_second</th>\n","      <th>test_mem_cpu_alloc_delta</th>\n","      <th>test_mem_gpu_alloc_delta</th>\n","      <th>test_mem_cpu_peaked_delta</th>\n","      <th>test_mem_gpu_peaked_delta</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000e+00</td>\n","      <td>3.0</td>\n","      <td>3.000000e+00</td>\n","      <td>3.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.489282</td>\n","      <td>0.845587</td>\n","      <td>0.845450</td>\n","      <td>0.846823</td>\n","      <td>0.845587</td>\n","      <td>451.274633</td>\n","      <td>55.398667</td>\n","      <td>-3.084288e+06</td>\n","      <td>0.0</td>\n","      <td>3.571712e+06</td>\n","      <td>8.982448e+08</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.001935</td>\n","      <td>0.001161</td>\n","      <td>0.001026</td>\n","      <td>0.002403</td>\n","      <td>0.001161</td>\n","      <td>0.173353</td>\n","      <td>0.021385</td>\n","      <td>6.648830e+06</td>\n","      <td>0.0</td>\n","      <td>6.186387e+06</td>\n","      <td>2.033006e+08</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.487325</td>\n","      <td>0.844320</td>\n","      <td>0.844320</td>\n","      <td>0.844323</td>\n","      <td>0.844320</td>\n","      <td>451.169000</td>\n","      <td>55.374000</td>\n","      <td>-1.071514e+07</td>\n","      <td>0.0</td>\n","      <td>0.000000e+00</td>\n","      <td>7.808691e+08</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.488326</td>\n","      <td>0.845080</td>\n","      <td>0.845014</td>\n","      <td>0.845676</td>\n","      <td>0.845080</td>\n","      <td>451.174600</td>\n","      <td>55.392000</td>\n","      <td>-5.357568e+06</td>\n","      <td>0.0</td>\n","      <td>0.000000e+00</td>\n","      <td>7.808691e+08</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.489327</td>\n","      <td>0.845840</td>\n","      <td>0.845708</td>\n","      <td>0.847030</td>\n","      <td>0.845840</td>\n","      <td>451.180200</td>\n","      <td>55.410000</td>\n","      <td>0.000000e+00</td>\n","      <td>0.0</td>\n","      <td>0.000000e+00</td>\n","      <td>7.808691e+08</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.490260</td>\n","      <td>0.846220</td>\n","      <td>0.846015</td>\n","      <td>0.848073</td>\n","      <td>0.846220</td>\n","      <td>451.327450</td>\n","      <td>55.411000</td>\n","      <td>7.311360e+05</td>\n","      <td>0.0</td>\n","      <td>5.357568e+06</td>\n","      <td>9.569326e+08</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>0.491194</td>\n","      <td>0.846600</td>\n","      <td>0.846323</td>\n","      <td>0.849115</td>\n","      <td>0.846600</td>\n","      <td>451.474700</td>\n","      <td>55.412000</td>\n","      <td>1.462272e+06</td>\n","      <td>0.0</td>\n","      <td>1.071514e+07</td>\n","      <td>1.132996e+09</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       test_loss  ...  test_mem_gpu_peaked_delta\n","count   3.000000  ...               3.000000e+00\n","mean    0.489282  ...               8.982448e+08\n","std     0.001935  ...               2.033006e+08\n","min     0.487325  ...               7.808691e+08\n","25%     0.488326  ...               7.808691e+08\n","50%     0.489327  ...               7.808691e+08\n","75%     0.490260  ...               9.569326e+08\n","max     0.491194  ...               1.132996e+09\n","\n","[8 rows x 11 columns]"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"0pHUcyA9gIfL"},"source":["Saving results"]},{"cell_type":"code","metadata":{"id":"pGyRffDBM3qH","executionInfo":{"status":"ok","timestamp":1619864514170,"user_tz":-480,"elapsed":6194657,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}}},"source":["\n","filepath = RESULTS_DIR+TASK_NAME\n","\n","# save adapter + classifier\n","if ADAPTER_NAME:\n","  model.save_adapter(filepath, TASK_NAME)\n","model.save_head(filepath, TASK_NAME)\n","\n","# dev and test results + hyperparameters used. hyperparameters will be in the same order dev_ and test_ results are appended\n","dev_df.to_excel(filepath+'/dev_results.xlsx',index=False)\n","test_df.to_excel(filepath+'/test_results.xlsx',index=False)\n","if ADAPTER_NAME:\n","  with open(filepath+'/hyperparameters.py', 'w') as writefile:\n","      writefile.write(\"HYPERPARAMETERS_SEARCH = {}\".format(HYPERPARAMETERS_SEARCH))\n","else:\n","  with open(filepath+'/hyperparameters.py', 'w') as writefile:\n","      writefile.write(\"HYPERPARAMETERS_SEARCH = {}\".format(hyperparameters_dict))"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"dmgfsM3OM3wT","executionInfo":{"status":"aborted","timestamp":1619857854960,"user_tz":-480,"elapsed":12245543,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"843wO0bteSmH","executionInfo":{"status":"aborted","timestamp":1619857854961,"user_tz":-480,"elapsed":12245542,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}}},"source":[""],"execution_count":null,"outputs":[]}]}