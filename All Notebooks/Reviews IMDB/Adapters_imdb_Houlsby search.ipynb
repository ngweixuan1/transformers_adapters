{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":" Adapters_imdb_Houlsby search.ipynb","provenance":[{"file_id":"1AxNR6W6r0ECHGb1OtxwtfSJPbtAKTPdW","timestamp":1619916534948},{"file_id":"1qDkodosI-REs-LqRomx0fyzmtIliDwi1","timestamp":1619353657436},{"file_id":"1jkthCAgVbiEwPYMJ2FQzHtrpiI71P7np","timestamp":1619324777840}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"3b0e74da3c6d45868d01c26f9a85e62d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_364afa7c00df439cac3130d649453dbd","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6743aab0f29a4e91a8e1aaa366a819d6","IPY_MODEL_6a06b27d9e3540f3a753cfe68ddf07ac"]}},"364afa7c00df439cac3130d649453dbd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6743aab0f29a4e91a8e1aaa366a819d6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_cf05edb83dc045568c2ef87acf7f1b8c","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":898823,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":898823,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9bec186d13e64797a882ef9f8bb52278"}},"6a06b27d9e3540f3a753cfe68ddf07ac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_98338634ae7d4b4299c5c80e359eb9cf","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 899k/899k [00:02&lt;00:00, 340kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7188a736772a43fbad8734d8c9801d95"}},"cf05edb83dc045568c2ef87acf7f1b8c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9bec186d13e64797a882ef9f8bb52278":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"98338634ae7d4b4299c5c80e359eb9cf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7188a736772a43fbad8734d8c9801d95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cd691983fabe4fd9b7d97f4bebe0d916":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0da512cc992b44f483441e22bfde038d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_dfacaf378898472bbc22270dad1deae7","IPY_MODEL_e403d2e42abc4af78cbe4a7896eec201"]}},"0da512cc992b44f483441e22bfde038d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dfacaf378898472bbc22270dad1deae7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ff26b97ce2374b56a64e53a3e43e697b","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9aa766395f4f48be9aa5bc47c30403ef"}},"e403d2e42abc4af78cbe4a7896eec201":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4122272596424af5aa9ff4e930356f72","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 456k/456k [00:01&lt;00:00, 322kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f0ce205f8857474da4beba5a7fd8dc9e"}},"ff26b97ce2374b56a64e53a3e43e697b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9aa766395f4f48be9aa5bc47c30403ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4122272596424af5aa9ff4e930356f72":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f0ce205f8857474da4beba5a7fd8dc9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"52855423724b4370a93bc25fde108215":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_888f6fb56c804730a4f73da5e561c825","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d61488ba2f234f979d5e4f72abd18475","IPY_MODEL_90ea77ebd37640ec9da7679b371a5620"]}},"888f6fb56c804730a4f73da5e561c825":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d61488ba2f234f979d5e4f72abd18475":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_03bca7aee85747ee8414159a507cf9be","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1355863,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1355863,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e58d3530ff074444981a2f4b3e49ba95"}},"90ea77ebd37640ec9da7679b371a5620":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6bdaa5b9101949a090f7bbfadbb031f9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.36M/1.36M [00:00&lt;00:00, 2.85MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e9904a42c0bc4e42a3efea21906e559d"}},"03bca7aee85747ee8414159a507cf9be":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e58d3530ff074444981a2f4b3e49ba95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6bdaa5b9101949a090f7bbfadbb031f9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e9904a42c0bc4e42a3efea21906e559d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f28485248f4841f4a0ad2255b273e56e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3e5d729db12a4aa5b59b409eacb3f28f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c8f1f4ebc7d5415b835baf6125c2a9ca","IPY_MODEL_52604e9edae24e64acb92f4e5f5e9ac5"]}},"3e5d729db12a4aa5b59b409eacb3f28f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c8f1f4ebc7d5415b835baf6125c2a9ca":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c9889e143d7d4345bee55081e618b9cb","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":481,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":481,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3a77c20c28d84b1d9019217fa500c996"}},"52604e9edae24e64acb92f4e5f5e9ac5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a7c1aa30d08a4603bc6d900355e04f48","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 481/481 [00:26&lt;00:00, 18.5B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_08b1610b1d5c4542885e369ab1d45fc6"}},"c9889e143d7d4345bee55081e618b9cb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3a77c20c28d84b1d9019217fa500c996":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a7c1aa30d08a4603bc6d900355e04f48":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"08b1610b1d5c4542885e369ab1d45fc6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"db5cc787e7ab46a8a05cacdb4531bb75":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0470d765f3664ccd91ca1e8c193c5620","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d94c5d0361504d0d9b95bfe85096b14a","IPY_MODEL_2de059b9a2b6458dac07a6701878b5af"]}},"0470d765f3664ccd91ca1e8c193c5620":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d94c5d0361504d0d9b95bfe85096b14a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1d07990cca0041198e2fa2026e09f431","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":501200538,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":501200538,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_078f6ca0b03f46bfb3e92c9ff2c2e4ff"}},"2de059b9a2b6458dac07a6701878b5af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_00d62d186ca24b07b45c09c2e4d6cb1c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 501M/501M [00:25&lt;00:00, 19.6MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fb7e097a5f3c48fc8da15d667a4dac5e"}},"1d07990cca0041198e2fa2026e09f431":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"078f6ca0b03f46bfb3e92c9ff2c2e4ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"00d62d186ca24b07b45c09c2e4d6cb1c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fb7e097a5f3c48fc8da15d667a4dac5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"lZj-G8LIXLpj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619917196920,"user_tz":-480,"elapsed":17683,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}},"outputId":"c7a9e1fe-1337-420f-cf1f-d4e9a75bea99"},"source":["# mount google drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","# log_dir='/content/gdrive/MyDrive/DL_Project/runs'\n","# !mkdir -p {log_dir}\n","# !mv ./runs/* {log_dir}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D61LwET3WrOD","executionInfo":{"status":"ok","timestamp":1619917319079,"user_tz":-480,"elapsed":139837,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}},"outputId":"af72696b-204e-4838-f2e1-8b21b552efc4"},"source":["!pip install -U git+https://github.com/Adapter-Hub/adapter-transformers.git@v2\n","!pip install torch==1.7.1\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/Adapter-Hub/adapter-transformers.git@v2\n","  Cloning https://github.com/Adapter-Hub/adapter-transformers.git (to revision v2) to /tmp/pip-req-build-kh04wq0o\n","  Running command git clone -q https://github.com/Adapter-Hub/adapter-transformers.git /tmp/pip-req-build-kh04wq0o\n","  Running command git checkout -b v2 --track origin/v2\n","  Switched to a new branch 'v2'\n","  Branch 'v2' set up to track remote branch 'v2' from 'origin'.\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from adapter-transformers==2.0.0a1) (2.23.0)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 8.4MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from adapter-transformers==2.0.0a1) (20.9)\n","Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from adapter-transformers==2.0.0a1) (3.10.1)\n","Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from adapter-transformers==2.0.0a1) (2019.12.20)\n","Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.7/dist-packages (from adapter-transformers==2.0.0a1) (3.0.12)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 27.9MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from adapter-transformers==2.0.0a1) (4.41.1)\n","Requirement already satisfied, skipping upgrade: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from adapter-transformers==2.0.0a1) (1.19.5)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->adapter-transformers==2.0.0a1) (3.0.4)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->adapter-transformers==2.0.0a1) (2020.12.5)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->adapter-transformers==2.0.0a1) (2.10)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->adapter-transformers==2.0.0a1) (1.24.3)\n","Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->adapter-transformers==2.0.0a1) (7.1.2)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->adapter-transformers==2.0.0a1) (1.15.0)\n","Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->adapter-transformers==2.0.0a1) (1.0.1)\n","Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->adapter-transformers==2.0.0a1) (2.4.7)\n","Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->adapter-transformers==2.0.0a1) (3.7.4.3)\n","Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->adapter-transformers==2.0.0a1) (3.4.1)\n","Building wheels for collected packages: adapter-transformers\n","  Building wheel for adapter-transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for adapter-transformers: filename=adapter_transformers-2.0.0a1-cp37-none-any.whl size=2097547 sha256=499fa76af44bec6043088c10749ac4deefabc7e5eb2cb13e85da51276604f170\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-glq8mn5z/wheels/11/c5/35/7017ef1a9923a73e9d8071801894534ab1fa662e38e23b78f1\n","Successfully built adapter-transformers\n","Installing collected packages: sacremoses, tokenizers, adapter-transformers\n","Successfully installed adapter-transformers-2.0.0a1 sacremoses-0.0.45 tokenizers-0.10.2\n","Collecting torch==1.7.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/5d/095ddddc91c8a769a68c791c019c5793f9c4456a688ddd235d6670924ecb/torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8MB)\n","\u001b[K     |████████████████████████████████| 776.8MB 23kB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1) (3.7.4.3)\n","\u001b[31mERROR: torchvision 0.9.1+cu101 has requirement torch==1.8.1, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n","Installing collected packages: torch\n","  Found existing installation: torch 1.8.1+cu101\n","    Uninstalling torch-1.8.1+cu101:\n","      Successfully uninstalled torch-1.8.1+cu101\n","Successfully installed torch-1.7.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DPpEKGrz_iNF","executionInfo":{"status":"ok","timestamp":1619917323371,"user_tz":-480,"elapsed":144124,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}},"outputId":"8f132b87-0503-4b00-e801-185954487caa"},"source":["import json, gc\n","import urllib.request\n","import numpy as np\n","import pandas as pd\n","import torch\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Using device:', device)\n","\n","from transformers import (\n","    MODEL_WITH_LM_HEAD_MAPPING,\n","    WEIGHTS_NAME,\n","    AdamW,\n","    AutoConfig,\n","    AutoModelWithLMHead,\n","    AutoTokenizer,\n","    PreTrainedModel,\n","    PreTrainedTokenizer,\n","    get_linear_schedule_with_warmup,\n","    RobertaTokenizer\n",")\n","from transformers import RobertaForSequenceClassification, RobertaModelWithHeads, RobertaConfig\n","from transformers import TrainingArguments, Trainer, EvalPrediction\n","\n","from sklearn import metrics\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","\n","from transformers import EarlyStoppingCallback\n","from transformers.integrations import TensorBoardCallback\n","from tensorflow import summary\n","import tensorflow\n","%load_ext tensorboard\n","import datetime"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using device: cuda\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wwRHoyT1Kwyl"},"source":["Dataset and Tokenizers"]},{"cell_type":"code","metadata":{"id":"m4NX9BQHHtVA"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tTjqSHp8IjOp","colab":{"base_uri":"https://localhost:8080/","height":163,"referenced_widgets":["3b0e74da3c6d45868d01c26f9a85e62d","364afa7c00df439cac3130d649453dbd","6743aab0f29a4e91a8e1aaa366a819d6","6a06b27d9e3540f3a753cfe68ddf07ac","cf05edb83dc045568c2ef87acf7f1b8c","9bec186d13e64797a882ef9f8bb52278","98338634ae7d4b4299c5c80e359eb9cf","7188a736772a43fbad8734d8c9801d95","cd691983fabe4fd9b7d97f4bebe0d916","0da512cc992b44f483441e22bfde038d","dfacaf378898472bbc22270dad1deae7","e403d2e42abc4af78cbe4a7896eec201","ff26b97ce2374b56a64e53a3e43e697b","9aa766395f4f48be9aa5bc47c30403ef","4122272596424af5aa9ff4e930356f72","f0ce205f8857474da4beba5a7fd8dc9e","52855423724b4370a93bc25fde108215","888f6fb56c804730a4f73da5e561c825","d61488ba2f234f979d5e4f72abd18475","90ea77ebd37640ec9da7679b371a5620","03bca7aee85747ee8414159a507cf9be","e58d3530ff074444981a2f4b3e49ba95","6bdaa5b9101949a090f7bbfadbb031f9","e9904a42c0bc4e42a3efea21906e559d"]},"executionInfo":{"status":"ok","timestamp":1619917326644,"user_tz":-480,"elapsed":147394,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}},"outputId":"5076c42f-8b99-4cc2-c286-df52d4e4cd1b"},"source":["DATASET = 'imdb'\n","tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3b0e74da3c6d45868d01c26f9a85e62d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cd691983fabe4fd9b7d97f4bebe0d916","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"52855423724b4370a93bc25fde108215","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355863.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RoTj34hLH6Ui","executionInfo":{"status":"ok","timestamp":1619917420901,"user_tz":-480,"elapsed":241647,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}},"outputId":"2d3948d8-b335-4a72-d1ae-ed29b16a0d59"},"source":["print(tokenizer.bos_token_id, tokenizer.bos_token, tokenizer.eos_token_id, tokenizer.eos_token)\n","MAX_SEQUENCE_LENGTH = 512\n","\n","\n","def load_and_tokenize(url, label2id={}, count_label = 0, tokenizer=tokenizer):\n","  # tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n","  block_size=512\n","  dataframe = []\n","  with urllib.request.urlopen(url) as f:\n","    for line in f:\n","      doc = json.loads(line.decode('utf-8'))['text']\n","      tokenized_text = tokenizer(doc, max_length=MAX_SEQUENCE_LENGTH, truncation=True, padding=\"max_length\")\n","      label = json.loads(line.decode('utf-8'))['label']\n","      \n","      if label not in label2id:\n","        label2id[label] = count_label\n","        count_label +=1\n","      tokenized_text['labels'] = torch.tensor(label2id[label])\n","      tokenized_text['input_ids'] = torch.tensor(tokenized_text['input_ids'])\n","      tokenized_text['attention_mask'] = torch.tensor(tokenized_text['attention_mask'])\n","      dataframe.append(tokenized_text)\n","  return dataframe, count_label, label2id\n","\n","train,count_label, label2id = load_and_tokenize(\"https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/\"+DATASET+\"/train.jsonl\", tokenizer=tokenizer)\n","dev,count_label,label2id = load_and_tokenize(\"https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/\"+DATASET+\"/dev.jsonl\",label2id,  count_label, tokenizer=tokenizer)\n","test,count_label,label2id = load_and_tokenize(\"https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/\"+DATASET+\"/test.jsonl\",label2id,  count_label, tokenizer=tokenizer)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0 <s> 2 </s>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ng0MCo9NH6XJ"},"source":["# config"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FKy95v85v3A4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619917420903,"user_tz":-480,"elapsed":241643,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}},"outputId":"d9abbfd3-2445-43b6-c15b-712abea4ed8d"},"source":["train[0]\n","print(len(train))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["20000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hTNu7bBNUJ7S"},"source":["Folder to save results"]},{"cell_type":"code","metadata":{"id":"U86TlZD8UJ7X"},"source":["RESULTS_DIR = f\"\"\"/content/drive/My Drive/DL_Project/results/imdb/Houlsby/search\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JAeAUGarJxb6"},"source":["General packages and functions"]},{"cell_type":"code","metadata":{"id":"LUAcaKKFJGeX"},"source":["from transformers import TrainingArguments, Trainer, EvalPrediction\n","def compute_accuracy(p: EvalPrediction):\n","    labels = p.label_ids\n","    preds = np.argmax(p.predictions, axis=1)\n","    acc = accuracy_score(labels, preds)\n","    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n","    return {\n","        'accuracy': acc,\n","        'f1': f1,\n","        'precision': precision,\n","        'recall': recall\n","    }\n","\n","from transformers import AdapterType, AdapterConfig, HoulsbyConfig"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LXIo9sQ2M43p"},"source":["def run_model(hyperparams_dict, model_name=\"roberta-base\",task_name=\"myown\",adapter_name=None,adapter_config=None,seed=999):\n","    global model\n","    config = RobertaConfig.from_pretrained(\n","        model_name,\n","        num_labels=len(label2id),\n","    )\n","    model = RobertaModelWithHeads.from_pretrained(\n","        model_name,\n","        config=config,\n","    )\n","\n","    if torch.cuda.is_available():\n","      model = model.to(\"cuda\")\n","    id2label= {v: k for k, v in label2id.items()}\n","    \n","    # Add a matching classification head\n","    model.add_classification_head(\n","        task_name,\n","        num_labels=len(label2id),\n","        id2label=id2label,\n","        layers=2\n","      )\n","    \n","    if adapter_name:\n","      # add a new adapter\n","      if adapter_config:\n","        model.add_adapter(\n","            task_name,\n","            ##### remove AdapterType argument for v2 #####\n","            #AdapterType.text_task,\n","            config=adapter_config\n","        )\n","      else:\n","        model.add_adapter(\n","            task_name,\n","            ##### remove AdapterType argument for v2 #####\n","            #AdapterType.text_task \n","        )\n","      # Enable adapter training\n","      model.train_adapter([task_name])\n","    \n","    # train, dev, test = get_datasets(tokenizer)\n","    training_args = TrainingArguments(\n","        learning_rate=hyperparams_dict['learning_rate'],\n","        num_train_epochs=hyperparams_dict['num_train_epochs'],\n","        per_device_train_batch_size=hyperparams_dict['per_device_train_batch_size'],\n","        per_device_eval_batch_size=hyperparams_dict['per_device_eval_batch_size'],\n","        logging_steps=hyperparams_dict['logging_steps'],\n","        save_steps=hyperparams_dict['save_steps'],\n","        output_dir='./models/'+task_name,\n","        overwrite_output_dir=True,\n","        do_train=True,\n","        do_eval=True,\n","        do_predict=True,\n","        evaluation_strategy='steps', # use evaluation_strategy='epoch' for v2, evaluation_strategy='step' for large dataset\n","        # The next line is important to ensure the dataset labels are properly passed to the model\n","        remove_unused_columns=False,\n","        load_best_model_at_end=True,\n","        metric_for_best_model=\"loss\",\n","        greater_is_better=False,\n","        seed=int(seed)\n","    )\n","\n","    # tensor_board = TensorBoardCallback()\n","    ##### Early Stopping #####\n","    es = EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.0)\n","    if adapter_name:\n","      trainer = Trainer(\n","          model=model,\n","          args=training_args,\n","          train_dataset=train,\n","          eval_dataset=dev,\n","          compute_metrics=compute_accuracy,\n","          callbacks=[es],\n","          adapter_names=[adapter_name]   \n","      )\n","    else:\n","      trainer = Trainer(\n","          model=model,\n","          args=training_args,\n","          train_dataset=train,\n","          eval_dataset=dev,\n","          callbacks=[es],\n","          compute_metrics=compute_accuracy\n","      )\n","    trainer.train()\n","\n","    ##### Explicitly set active adapter to pass it in model forward pass,             #####\n","    ##### otherwise the previous setting adapter_names=[adapter_name] not work for v2 #####\n","    if adapter_name:\n","      trainer.model.set_active_adapters(adapter_name)\n","\n","    _, _, metrics = trainer.predict(dev)\n","    metrics['seed'] = seed\n","    dev_results.append(pd.DataFrame.from_dict(metrics, orient='index').T)\n","\n","    metrics['seed'] = seed\n","    _, _, metrics = trainer.predict(test)\n","    test_results.append(pd.DataFrame.from_dict(metrics, orient='index').T)\n","    \n","    filepath = RESULTS_DIR + \"\"\"{}_{}_{}\"\"\".format(task_name,seed,timestamp.strftime(\"%Y-%m-%dT%H_%M_%S\"))\n","    filepath = filepath + '_' + str(hyperparams_dict['learning_rate']) \\\n","                + '_' + str(hyperparams_dict['num_train_epochs']) \\\n","                + '_' + str(hyperparams_dict['per_device_train_batch_size'] ) \\\n","                + '_' + str(hyperparams_dict['per_device_eval_batch_size']) \\\n","                + '_' + str(hyperparams_dict['logging_steps']) \\\n","                + '_' + str(hyperparams_dict['save_steps'])\n","    trainer.save_model(filepath)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CH189097M2Aq"},"source":["### Model: RoBERTa Base\n","### Task: Reviews\n","### Finetuning: Standard with classification head\n","### Adapter: None (None /Custom /Default / Houlsby / Pfeiffer)"]},{"cell_type":"code","metadata":{"id":"o-WVVlNqM2Aq"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4lqaOie3M2Aq"},"source":["# MODEL_NAME = \"allenai/cs_roberta_base\"\n","MODEL_NAME = \"roberta-base\"\n","TASK_NAME = \"imdb_Houlsby_finetune\" # cit_intent_base_myownadapter / cit_intent_base_pfieffer\n","ADAPTER_NAME = \"imdb_Houlsby_finetune\" # None pfieffer / cit_intent_base_finetune\n","\n","\n","ADAPTER_CONFIG = HoulsbyConfig() # leave ADAPTER_CONFIG as None to default adapter\n","\n","# ADAPTER_CONFIG = AdapterConfig.load( # comment out if using default adapter\n","#     # adapter_args.adapter_config,\n","#     # non_linearity=adapter_args.adapter_non_linearity,\n","#     # reduction_factor=adapter_args.adapter_reduction_factor,\n","#     ADAPTER_NAME, \n","#     # non_linearity=adapter_args.adapter_non_linearity,\n","#     reduction_factor=12\n","# )\n","\n","# hyperparameters search\n","#hyperparameters_dict = {'learning_rate':2e-5,'num_train_epochs':3,'per_device_train_batch_size':16,'per_device_eval_batch_size':16,'logging_steps':1000,'save_steps':1000} # hyperparameters for standard finetuning\n","\n","HYPERPARAMETERS_SEARCH = [{'learning_rate':1e-4,'num_train_epochs':10,'per_device_train_batch_size':16,'per_device_eval_batch_size':16,'logging_steps':1000,'save_steps':1000},\n","                          {'learning_rate':8e-5,'num_train_epochs':10,'per_device_train_batch_size':16,'per_device_eval_batch_size':16,'logging_steps':1000,'save_steps':1000},\n","                          {'learning_rate':2e-5,'num_train_epochs':10,'per_device_train_batch_size':16,'per_device_eval_batch_size':16,'logging_steps':1000,'save_steps':1000},\n","\n","                          ]\n","\n","#HYPERPARAMETERS_SEARCH = [ {'learning_rate':8e-5,'num_train_epochs':10,'per_device_train_batch_size':16,'per_device_eval_batch_size':16,'logging_steps':1000,'save_steps':1000}]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u52XtNy1M2Aq","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f28485248f4841f4a0ad2255b273e56e","3e5d729db12a4aa5b59b409eacb3f28f","c8f1f4ebc7d5415b835baf6125c2a9ca","52604e9edae24e64acb92f4e5f5e9ac5","c9889e143d7d4345bee55081e618b9cb","3a77c20c28d84b1d9019217fa500c996","a7c1aa30d08a4603bc6d900355e04f48","08b1610b1d5c4542885e369ab1d45fc6","db5cc787e7ab46a8a05cacdb4531bb75","0470d765f3664ccd91ca1e8c193c5620","d94c5d0361504d0d9b95bfe85096b14a","2de059b9a2b6458dac07a6701878b5af","1d07990cca0041198e2fa2026e09f431","078f6ca0b03f46bfb3e92c9ff2c2e4ff","00d62d186ca24b07b45c09c2e4d6cb1c","fb7e097a5f3c48fc8da15d667a4dac5e"]},"executionInfo":{"status":"ok","timestamp":1619936435962,"user_tz":-480,"elapsed":19256689,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}},"outputId":"662a2229-d454-4337-bca1-fe71df017976"},"source":["\n","\n","from datetime import datetime, timedelta\n","timestamp = datetime.today() + timedelta(hours=8)\n","tokenizer = RobertaTokenizer.from_pretrained(MODEL_NAME)\n","print(tokenizer.bos_token_id, tokenizer.bos_token, tokenizer.eos_token_id, tokenizer.eos_token)\n","\n","seeds = [1,2,42]\n","dev_results = []\n","test_results = []\n","print('seeds:', seeds)\n","\n","if ADAPTER_NAME:\n","    # if using adapter, loop by HYPERPARAMETERS_SEARCH defined above\n","    for hyperparameters_dict in HYPERPARAMETERS_SEARCH:\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        print(hyperparameters_dict)\n","        run_model(hyperparameters_dict, model_name=MODEL_NAME,task_name=TASK_NAME,adapter_name=ADAPTER_NAME,adapter_config=ADAPTER_CONFIG)\n","else: # if not using adapter, assume standard finetuning and loop by seeds\n","    for seed in seeds:\n","        print(type(int(seed)))\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        print(hyperparameters_dict)\n","        run_model(hyperparameters_dict, model_name=MODEL_NAME,task_name=TASK_NAME,adapter_name=ADAPTER_NAME,adapter_config=ADAPTER_CONFIG, seed=seed)\n","\n","dev_df = pd.concat(dev_results)\n","test_df = pd.concat(test_results)\n","\n","\n","# UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior._warn_prf(average, modifier, msg_start, len(result))\n","## some labels in y_test don't appear in y_pred. "],"execution_count":null,"outputs":[{"output_type":"stream","text":["0 <s> 2 </s>\n","seeds: [1, 2, 42]\n","{'learning_rate': 0.0001, 'num_train_epochs': 10, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 16, 'logging_steps': 1000, 'save_steps': 1000}\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f28485248f4841f4a0ad2255b273e56e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"db5cc787e7ab46a8a05cacdb4531bb75","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=501200538.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='6000' max='12500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 6000/12500 1:22:24 < 1:29:17, 1.21 it/s, Epoch 4/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Runtime</th>\n","      <th>Samples Per Second</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.254100</td>\n","      <td>0.144607</td>\n","      <td>0.944200</td>\n","      <td>0.944199</td>\n","      <td>0.944221</td>\n","      <td>0.944200</td>\n","      <td>93.418200</td>\n","      <td>53.523000</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.159600</td>\n","      <td>0.150367</td>\n","      <td>0.948400</td>\n","      <td>0.948398</td>\n","      <td>0.948473</td>\n","      <td>0.948400</td>\n","      <td>93.461100</td>\n","      <td>53.498000</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.151400</td>\n","      <td>0.141243</td>\n","      <td>0.951400</td>\n","      <td>0.951399</td>\n","      <td>0.951453</td>\n","      <td>0.951400</td>\n","      <td>93.479100</td>\n","      <td>53.488000</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.131300</td>\n","      <td>0.167615</td>\n","      <td>0.949000</td>\n","      <td>0.948987</td>\n","      <td>0.949472</td>\n","      <td>0.949000</td>\n","      <td>93.545400</td>\n","      <td>53.450000</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.119700</td>\n","      <td>0.144923</td>\n","      <td>0.953200</td>\n","      <td>0.953197</td>\n","      <td>0.953305</td>\n","      <td>0.953200</td>\n","      <td>93.463000</td>\n","      <td>53.497000</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.103900</td>\n","      <td>0.149534</td>\n","      <td>0.954000</td>\n","      <td>0.954000</td>\n","      <td>0.954010</td>\n","      <td>0.954000</td>\n","      <td>93.482700</td>\n","      <td>53.486000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='1876' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [313/313 09:20]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["{'learning_rate': 8e-05, 'num_train_epochs': 10, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 16, 'logging_steps': 1000, 'save_steps': 1000}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='6000' max='12500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 6000/12500 1:22:14 < 1:29:07, 1.22 it/s, Epoch 4/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Runtime</th>\n","      <th>Samples Per Second</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.256000</td>\n","      <td>0.145543</td>\n","      <td>0.944200</td>\n","      <td>0.944200</td>\n","      <td>0.944209</td>\n","      <td>0.944200</td>\n","      <td>93.435700</td>\n","      <td>53.513000</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.161300</td>\n","      <td>0.149770</td>\n","      <td>0.946600</td>\n","      <td>0.946598</td>\n","      <td>0.946678</td>\n","      <td>0.946600</td>\n","      <td>93.480500</td>\n","      <td>53.487000</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.155700</td>\n","      <td>0.141153</td>\n","      <td>0.951800</td>\n","      <td>0.951800</td>\n","      <td>0.951804</td>\n","      <td>0.951800</td>\n","      <td>93.483400</td>\n","      <td>53.485000</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.137000</td>\n","      <td>0.162529</td>\n","      <td>0.948400</td>\n","      <td>0.948390</td>\n","      <td>0.948732</td>\n","      <td>0.948400</td>\n","      <td>93.446300</td>\n","      <td>53.507000</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.126900</td>\n","      <td>0.145418</td>\n","      <td>0.953200</td>\n","      <td>0.953199</td>\n","      <td>0.953235</td>\n","      <td>0.953200</td>\n","      <td>93.509100</td>\n","      <td>53.471000</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.113000</td>\n","      <td>0.144528</td>\n","      <td>0.951600</td>\n","      <td>0.951599</td>\n","      <td>0.951642</td>\n","      <td>0.951600</td>\n","      <td>93.501800</td>\n","      <td>53.475000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='1876' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [313/313 09:20]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["{'learning_rate': 2e-05, 'num_train_epochs': 10, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 16, 'logging_steps': 1000, 'save_steps': 1000}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='9000' max='12500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 9000/12500 2:03:11 < 47:55, 1.22 it/s, Epoch 7/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Runtime</th>\n","      <th>Samples Per Second</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.374100</td>\n","      <td>0.189403</td>\n","      <td>0.930000</td>\n","      <td>0.929993</td>\n","      <td>0.930172</td>\n","      <td>0.930000</td>\n","      <td>93.479100</td>\n","      <td>53.488000</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.186400</td>\n","      <td>0.168015</td>\n","      <td>0.935200</td>\n","      <td>0.935200</td>\n","      <td>0.935200</td>\n","      <td>0.935200</td>\n","      <td>93.466700</td>\n","      <td>53.495000</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.180400</td>\n","      <td>0.157980</td>\n","      <td>0.942200</td>\n","      <td>0.942197</td>\n","      <td>0.942277</td>\n","      <td>0.942200</td>\n","      <td>93.466600</td>\n","      <td>53.495000</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.163500</td>\n","      <td>0.160574</td>\n","      <td>0.945800</td>\n","      <td>0.945797</td>\n","      <td>0.945898</td>\n","      <td>0.945800</td>\n","      <td>93.492100</td>\n","      <td>53.480000</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.160800</td>\n","      <td>0.157048</td>\n","      <td>0.945800</td>\n","      <td>0.945788</td>\n","      <td>0.946180</td>\n","      <td>0.945800</td>\n","      <td>93.457200</td>\n","      <td>53.500000</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.152200</td>\n","      <td>0.149526</td>\n","      <td>0.947600</td>\n","      <td>0.947600</td>\n","      <td>0.947603</td>\n","      <td>0.947600</td>\n","      <td>93.481600</td>\n","      <td>53.486000</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.156900</td>\n","      <td>0.149603</td>\n","      <td>0.947600</td>\n","      <td>0.947592</td>\n","      <td>0.947858</td>\n","      <td>0.947600</td>\n","      <td>93.416100</td>\n","      <td>53.524000</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>0.142900</td>\n","      <td>0.150296</td>\n","      <td>0.948400</td>\n","      <td>0.948400</td>\n","      <td>0.948401</td>\n","      <td>0.948400</td>\n","      <td>93.436200</td>\n","      <td>53.512000</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>0.144200</td>\n","      <td>0.149575</td>\n","      <td>0.949200</td>\n","      <td>0.949199</td>\n","      <td>0.949218</td>\n","      <td>0.949200</td>\n","      <td>93.439100</td>\n","      <td>53.511000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='1876' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [313/313 09:20]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"g5yMbjcAM2Ar","colab":{"base_uri":"https://localhost:8080/","height":832},"executionInfo":{"status":"ok","timestamp":1619936435966,"user_tz":-480,"elapsed":19256688,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}},"outputId":"4165f774-91e5-413b-88b5-1e349159d2c7"},"source":["display(dev_df)\n","display(dev_df.describe())\n","\n","display(test_df)\n","display(test_df.describe())"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>test_loss</th>\n","      <th>test_accuracy</th>\n","      <th>test_f1</th>\n","      <th>test_precision</th>\n","      <th>test_recall</th>\n","      <th>test_runtime</th>\n","      <th>test_samples_per_second</th>\n","      <th>test_mem_cpu_alloc_delta</th>\n","      <th>test_mem_gpu_alloc_delta</th>\n","      <th>test_mem_cpu_peaked_delta</th>\n","      <th>test_mem_gpu_peaked_delta</th>\n","      <th>seed</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.141243</td>\n","      <td>0.9514</td>\n","      <td>0.951399</td>\n","      <td>0.951453</td>\n","      <td>0.9514</td>\n","      <td>93.4644</td>\n","      <td>53.496</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>755290112.0</td>\n","      <td>999.0</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>0.141153</td>\n","      <td>0.9518</td>\n","      <td>0.951800</td>\n","      <td>0.951804</td>\n","      <td>0.9518</td>\n","      <td>93.4255</td>\n","      <td>53.519</td>\n","      <td>0.0</td>\n","      <td>-132096.0</td>\n","      <td>0.0</td>\n","      <td>758444544.0</td>\n","      <td>999.0</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>0.149526</td>\n","      <td>0.9476</td>\n","      <td>0.947600</td>\n","      <td>0.947603</td>\n","      <td>0.9476</td>\n","      <td>93.4132</td>\n","      <td>53.526</td>\n","      <td>-40960.0</td>\n","      <td>0.0</td>\n","      <td>40960.0</td>\n","      <td>808762368.0</td>\n","      <td>999.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   test_loss  test_accuracy  ...  test_mem_gpu_peaked_delta   seed\n","0   0.141243         0.9514  ...                755290112.0  999.0\n","0   0.141153         0.9518  ...                758444544.0  999.0\n","0   0.149526         0.9476  ...                808762368.0  999.0\n","\n","[3 rows x 12 columns]"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>test_loss</th>\n","      <th>test_accuracy</th>\n","      <th>test_f1</th>\n","      <th>test_precision</th>\n","      <th>test_recall</th>\n","      <th>test_runtime</th>\n","      <th>test_samples_per_second</th>\n","      <th>test_mem_cpu_alloc_delta</th>\n","      <th>test_mem_gpu_alloc_delta</th>\n","      <th>test_mem_cpu_peaked_delta</th>\n","      <th>test_mem_gpu_peaked_delta</th>\n","      <th>seed</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000e+00</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.143974</td>\n","      <td>0.950267</td>\n","      <td>0.950266</td>\n","      <td>0.950286</td>\n","      <td>0.950267</td>\n","      <td>93.434367</td>\n","      <td>53.513667</td>\n","      <td>-13653.333333</td>\n","      <td>-44032.000000</td>\n","      <td>13653.333333</td>\n","      <td>7.741657e+08</td>\n","      <td>999.0</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.004809</td>\n","      <td>0.002318</td>\n","      <td>0.002318</td>\n","      <td>0.002331</td>\n","      <td>0.002318</td>\n","      <td>0.026727</td>\n","      <td>0.015695</td>\n","      <td>23648.267026</td>\n","      <td>76265.661159</td>\n","      <td>23648.267026</td>\n","      <td>3.000310e+07</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.141153</td>\n","      <td>0.947600</td>\n","      <td>0.947600</td>\n","      <td>0.947603</td>\n","      <td>0.947600</td>\n","      <td>93.413200</td>\n","      <td>53.496000</td>\n","      <td>-40960.000000</td>\n","      <td>-132096.000000</td>\n","      <td>0.000000</td>\n","      <td>7.552901e+08</td>\n","      <td>999.0</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.141198</td>\n","      <td>0.949500</td>\n","      <td>0.949499</td>\n","      <td>0.949528</td>\n","      <td>0.949500</td>\n","      <td>93.419350</td>\n","      <td>53.507500</td>\n","      <td>-20480.000000</td>\n","      <td>-66048.000000</td>\n","      <td>0.000000</td>\n","      <td>7.568673e+08</td>\n","      <td>999.0</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.141243</td>\n","      <td>0.951400</td>\n","      <td>0.951399</td>\n","      <td>0.951453</td>\n","      <td>0.951400</td>\n","      <td>93.425500</td>\n","      <td>53.519000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>7.584445e+08</td>\n","      <td>999.0</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.145385</td>\n","      <td>0.951600</td>\n","      <td>0.951599</td>\n","      <td>0.951628</td>\n","      <td>0.951600</td>\n","      <td>93.444950</td>\n","      <td>53.522500</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>20480.000000</td>\n","      <td>7.836035e+08</td>\n","      <td>999.0</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>0.149526</td>\n","      <td>0.951800</td>\n","      <td>0.951800</td>\n","      <td>0.951804</td>\n","      <td>0.951800</td>\n","      <td>93.464400</td>\n","      <td>53.526000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>40960.000000</td>\n","      <td>8.087624e+08</td>\n","      <td>999.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       test_loss  test_accuracy  ...  test_mem_gpu_peaked_delta   seed\n","count   3.000000       3.000000  ...               3.000000e+00    3.0\n","mean    0.143974       0.950267  ...               7.741657e+08  999.0\n","std     0.004809       0.002318  ...               3.000310e+07    0.0\n","min     0.141153       0.947600  ...               7.552901e+08  999.0\n","25%     0.141198       0.949500  ...               7.568673e+08  999.0\n","50%     0.141243       0.951400  ...               7.584445e+08  999.0\n","75%     0.145385       0.951600  ...               7.836035e+08  999.0\n","max     0.149526       0.951800  ...               8.087624e+08  999.0\n","\n","[8 rows x 12 columns]"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>test_loss</th>\n","      <th>test_accuracy</th>\n","      <th>test_f1</th>\n","      <th>test_precision</th>\n","      <th>test_recall</th>\n","      <th>test_runtime</th>\n","      <th>test_samples_per_second</th>\n","      <th>test_mem_cpu_alloc_delta</th>\n","      <th>test_mem_gpu_alloc_delta</th>\n","      <th>test_mem_cpu_peaked_delta</th>\n","      <th>test_mem_gpu_peaked_delta</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.135327</td>\n","      <td>0.95236</td>\n","      <td>0.952359</td>\n","      <td>0.952381</td>\n","      <td>0.95236</td>\n","      <td>467.2650</td>\n","      <td>53.503</td>\n","      <td>331776.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>809101312.0</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>0.136473</td>\n","      <td>0.95268</td>\n","      <td>0.952680</td>\n","      <td>0.952695</td>\n","      <td>0.95268</td>\n","      <td>467.1397</td>\n","      <td>53.517</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>807394304.0</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>0.143140</td>\n","      <td>0.94928</td>\n","      <td>0.949280</td>\n","      <td>0.949292</td>\n","      <td>0.94928</td>\n","      <td>467.0935</td>\n","      <td>53.522</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>809166848.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   test_loss  ...  test_mem_gpu_peaked_delta\n","0   0.135327  ...                809101312.0\n","0   0.136473  ...                807394304.0\n","0   0.143140  ...                809166848.0\n","\n","[3 rows x 11 columns]"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>test_loss</th>\n","      <th>test_accuracy</th>\n","      <th>test_f1</th>\n","      <th>test_precision</th>\n","      <th>test_recall</th>\n","      <th>test_runtime</th>\n","      <th>test_samples_per_second</th>\n","      <th>test_mem_cpu_alloc_delta</th>\n","      <th>test_mem_gpu_alloc_delta</th>\n","      <th>test_mem_cpu_peaked_delta</th>\n","      <th>test_mem_gpu_peaked_delta</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.138313</td>\n","      <td>0.951440</td>\n","      <td>0.951440</td>\n","      <td>0.951456</td>\n","      <td>0.951440</td>\n","      <td>467.166067</td>\n","      <td>53.514000</td>\n","      <td>110592.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.085542e+08</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.004219</td>\n","      <td>0.001877</td>\n","      <td>0.001877</td>\n","      <td>0.001881</td>\n","      <td>0.001877</td>\n","      <td>0.088738</td>\n","      <td>0.009849</td>\n","      <td>191550.962911</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.004994e+06</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.135327</td>\n","      <td>0.949280</td>\n","      <td>0.949280</td>\n","      <td>0.949292</td>\n","      <td>0.949280</td>\n","      <td>467.093500</td>\n","      <td>53.503000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.073943e+08</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.135900</td>\n","      <td>0.950820</td>\n","      <td>0.950820</td>\n","      <td>0.950836</td>\n","      <td>0.950820</td>\n","      <td>467.116600</td>\n","      <td>53.510000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.082478e+08</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.136473</td>\n","      <td>0.952360</td>\n","      <td>0.952359</td>\n","      <td>0.952381</td>\n","      <td>0.952360</td>\n","      <td>467.139700</td>\n","      <td>53.517000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.091013e+08</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.139806</td>\n","      <td>0.952520</td>\n","      <td>0.952520</td>\n","      <td>0.952538</td>\n","      <td>0.952520</td>\n","      <td>467.202350</td>\n","      <td>53.519500</td>\n","      <td>165888.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.091341e+08</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>0.143140</td>\n","      <td>0.952680</td>\n","      <td>0.952680</td>\n","      <td>0.952695</td>\n","      <td>0.952680</td>\n","      <td>467.265000</td>\n","      <td>53.522000</td>\n","      <td>331776.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.091668e+08</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       test_loss  ...  test_mem_gpu_peaked_delta\n","count   3.000000  ...               3.000000e+00\n","mean    0.138313  ...               8.085542e+08\n","std     0.004219  ...               1.004994e+06\n","min     0.135327  ...               8.073943e+08\n","25%     0.135900  ...               8.082478e+08\n","50%     0.136473  ...               8.091013e+08\n","75%     0.139806  ...               8.091341e+08\n","max     0.143140  ...               8.091668e+08\n","\n","[8 rows x 11 columns]"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"0pHUcyA9gIfL"},"source":["Saving results"]},{"cell_type":"code","metadata":{"id":"pGyRffDBM3qH"},"source":["\n","filepath = RESULTS_DIR+TASK_NAME\n","\n","# save adapter + classifier\n","if ADAPTER_NAME:\n","  model.save_adapter(filepath, TASK_NAME)\n","model.save_head(filepath, TASK_NAME)\n","\n","# dev and test results + hyperparameters used. hyperparameters will be in the same order dev_ and test_ results are appended\n","dev_df.to_excel(filepath+'/dev_results.xlsx',index=False)\n","test_df.to_excel(filepath+'/test_results.xlsx',index=False)\n","if ADAPTER_NAME:\n","  with open(filepath+'/hyperparameters.py', 'w') as writefile:\n","      writefile.write(\"HYPERPARAMETERS_SEARCH = {}\".format(HYPERPARAMETERS_SEARCH))\n","else:\n","  with open(filepath+'/hyperparameters.py', 'w') as writefile:\n","      writefile.write(\"HYPERPARAMETERS_SEARCH = {}\".format(hyperparameters_dict))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dmgfsM3OM3wT"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"843wO0bteSmH"},"source":[""],"execution_count":null,"outputs":[]}]}