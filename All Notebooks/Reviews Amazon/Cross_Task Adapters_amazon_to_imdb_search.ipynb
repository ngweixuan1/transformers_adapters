{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Cross_Task Adapters_amazon_to_imdb_search.ipynb","provenance":[{"file_id":"1gxddX4gig3SnW4xir9KViJ7uhp3P7mBM","timestamp":1619933205559},{"file_id":"1jkthCAgVbiEwPYMJ2FQzHtrpiI71P7np","timestamp":1619613656824}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"7e55fa159bc34c7ca56ee215eddaaa5e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4139b521eb4647bfa32f40a9f69f6a21","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3be5351a53124cb2aecfa5f27f6fcb17","IPY_MODEL_12540c27ad5f4b78a7657fb1b1fe1469"]}},"4139b521eb4647bfa32f40a9f69f6a21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3be5351a53124cb2aecfa5f27f6fcb17":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_fd4754ec60e44121aca94cc21d7e1627","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":898823,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":898823,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cee0217fd43548609aa6f991ad931be8"}},"12540c27ad5f4b78a7657fb1b1fe1469":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_edcb6c291411405ca7a3b72e69636b66","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 899k/899k [00:02&lt;00:00, 345kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6bb264a03a2543bbaca480e6032457c1"}},"fd4754ec60e44121aca94cc21d7e1627":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"cee0217fd43548609aa6f991ad931be8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"edcb6c291411405ca7a3b72e69636b66":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6bb264a03a2543bbaca480e6032457c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7fd3d84720604e068de45772689a1eb7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_aa8b8b2fff4543129ac8180398db79ad","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_14142725a1234b0b89ef7e3cb082d02b","IPY_MODEL_57cb5cbffb19490c9acfd2d3cd3dc293"]}},"aa8b8b2fff4543129ac8180398db79ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"14142725a1234b0b89ef7e3cb082d02b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2193a2ae73f1446eb9ac63d529de8271","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c872d08812f542d29f2fd5a3c34f8f38"}},"57cb5cbffb19490c9acfd2d3cd3dc293":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_eb49d36ef3f741da9265a0084233f0a9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 456k/456k [00:01&lt;00:00, 254kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a18a307d98664bce95abb2b4a2037792"}},"2193a2ae73f1446eb9ac63d529de8271":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c872d08812f542d29f2fd5a3c34f8f38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"eb49d36ef3f741da9265a0084233f0a9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a18a307d98664bce95abb2b4a2037792":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9911544e46c74a8c8573beefe8cb183c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_32fd8aa6a8d04e65b7c938408e1e5f5c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b6fbbf5e98cb4c818c09c96c156ceb86","IPY_MODEL_709719d8086f4c7c91d4e5d9084b0780"]}},"32fd8aa6a8d04e65b7c938408e1e5f5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b6fbbf5e98cb4c818c09c96c156ceb86":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f95c1ffd59f34926a3479f5b30839324","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1355863,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1355863,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a79b26f4edee47a69c355f731c5549d1"}},"709719d8086f4c7c91d4e5d9084b0780":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6ffefd974ac845bfb7d19717121757d5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.36M/1.36M [00:00&lt;00:00, 3.04MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7e3849e5ed834445a1bc4c5b077ff9c7"}},"f95c1ffd59f34926a3479f5b30839324":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a79b26f4edee47a69c355f731c5549d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6ffefd974ac845bfb7d19717121757d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7e3849e5ed834445a1bc4c5b077ff9c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9f07fe4827dc49f5b7824253618cace8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bb94f485c18646589733d0baadf36f60","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_52ab9e924ad84e6cb6a52b48628fe48b","IPY_MODEL_b0c89e55ff454e20b9684cfc0638b52b"]}},"bb94f485c18646589733d0baadf36f60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"52ab9e924ad84e6cb6a52b48628fe48b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7ca0e648266548598d227f62a5d0f813","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":481,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":481,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1fded96945fc4fff8de855316475caf2"}},"b0c89e55ff454e20b9684cfc0638b52b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cea11fa54db2424bad3140fc4037c6ad","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 481/481 [00:20&lt;00:00, 23.3B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5a8b427263e948808a82b8382aa60515"}},"7ca0e648266548598d227f62a5d0f813":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1fded96945fc4fff8de855316475caf2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cea11fa54db2424bad3140fc4037c6ad":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5a8b427263e948808a82b8382aa60515":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d91b492a0651449db688cfd8377fa1f7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ff45bfeb88274fbb976c62bec033638f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b14c0ee666de452da2671205bf761a51","IPY_MODEL_f37919463b2d4d17b2b102942d9fbeb5"]}},"ff45bfeb88274fbb976c62bec033638f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b14c0ee666de452da2671205bf761a51":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_033ffbedd6c14d3c98c6078289ff869e","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":501200538,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":501200538,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_625d450e3a884261945af98e50b80f89"}},"f37919463b2d4d17b2b102942d9fbeb5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4ceaa96e7e04486ca05e687fff833ceb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 501M/501M [00:20&lt;00:00, 24.9MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c6aaab789695412d99fc57e950e91234"}},"033ffbedd6c14d3c98c6078289ff869e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"625d450e3a884261945af98e50b80f89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4ceaa96e7e04486ca05e687fff833ceb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c6aaab789695412d99fc57e950e91234":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"lZj-G8LIXLpj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619933590961,"user_tz":-480,"elapsed":357369,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}},"outputId":"684e2fcb-d351-4b88-a2e6-96888e851669"},"source":["# mount google drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","# log_dir='/content/gdrive/MyDrive/DL_Project/runs'\n","# !mkdir -p {log_dir}\n","# !mv ./runs/* {log_dir}"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D61LwET3WrOD","executionInfo":{"status":"ok","timestamp":1619933710574,"user_tz":-480,"elapsed":476978,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}},"outputId":"c924ba0e-efc3-4bb3-b139-d0d4c6424b4d"},"source":["!pip install -U git+https://github.com/Adapter-Hub/adapter-transformers.git@v2\n","!pip install torch==1.7.1\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/Adapter-Hub/adapter-transformers.git@v2\n","  Cloning https://github.com/Adapter-Hub/adapter-transformers.git (to revision v2) to /tmp/pip-req-build-53lq1i3_\n","  Running command git clone -q https://github.com/Adapter-Hub/adapter-transformers.git /tmp/pip-req-build-53lq1i3_\n","  Running command git checkout -b v2 --track origin/v2\n","  Switched to a new branch 'v2'\n","  Branch 'v2' set up to track remote branch 'v2' from 'origin'.\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied, skipping upgrade: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from adapter-transformers==2.0.0a1) (4.41.1)\n","Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from adapter-transformers==2.0.0a1) (2019.12.20)\n","Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from adapter-transformers==2.0.0a1) (3.10.1)\n","Requirement already satisfied, skipping upgrade: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from adapter-transformers==2.0.0a1) (1.19.5)\n","Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.7/dist-packages (from adapter-transformers==2.0.0a1) (3.0.12)\n","Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from adapter-transformers==2.0.0a1) (20.9)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 8.3MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 28.2MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from adapter-transformers==2.0.0a1) (2.23.0)\n","Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->adapter-transformers==2.0.0a1) (3.7.4.3)\n","Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->adapter-transformers==2.0.0a1) (3.4.1)\n","Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->adapter-transformers==2.0.0a1) (2.4.7)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->adapter-transformers==2.0.0a1) (1.15.0)\n","Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->adapter-transformers==2.0.0a1) (1.0.1)\n","Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->adapter-transformers==2.0.0a1) (7.1.2)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->adapter-transformers==2.0.0a1) (2.10)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->adapter-transformers==2.0.0a1) (3.0.4)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->adapter-transformers==2.0.0a1) (2020.12.5)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->adapter-transformers==2.0.0a1) (1.24.3)\n","Building wheels for collected packages: adapter-transformers\n","  Building wheel for adapter-transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for adapter-transformers: filename=adapter_transformers-2.0.0a1-cp37-none-any.whl size=2097547 sha256=d14f5ccbdabd0367d181febdbec675b164427940e2a04d3def5cf64cf69898ad\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-rl2k5_n9/wheels/11/c5/35/7017ef1a9923a73e9d8071801894534ab1fa662e38e23b78f1\n","Successfully built adapter-transformers\n","Installing collected packages: sacremoses, tokenizers, adapter-transformers\n","Successfully installed adapter-transformers-2.0.0a1 sacremoses-0.0.45 tokenizers-0.10.2\n","Collecting torch==1.7.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/5d/095ddddc91c8a769a68c791c019c5793f9c4456a688ddd235d6670924ecb/torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8MB)\n","\u001b[K     |████████████████████████████████| 776.8MB 24kB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1) (3.7.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1) (1.19.5)\n","\u001b[31mERROR: torchvision 0.9.1+cu101 has requirement torch==1.8.1, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n","Installing collected packages: torch\n","  Found existing installation: torch 1.8.1+cu101\n","    Uninstalling torch-1.8.1+cu101:\n","      Successfully uninstalled torch-1.8.1+cu101\n","Successfully installed torch-1.7.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DPpEKGrz_iNF","executionInfo":{"status":"ok","timestamp":1619933714116,"user_tz":-480,"elapsed":480516,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}},"outputId":"87a2df2a-033e-464b-8b7a-10e594522d56"},"source":["import json, gc\n","import urllib.request\n","import numpy as np\n","import pandas as pd\n","import torch\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Using device:', device)\n","\n","from transformers import (\n","    MODEL_WITH_LM_HEAD_MAPPING,\n","    WEIGHTS_NAME,\n","    AdamW,\n","    AutoConfig,\n","    AutoModelWithLMHead,\n","    AutoTokenizer,\n","    PreTrainedModel,\n","    PreTrainedTokenizer,\n","    get_linear_schedule_with_warmup,\n","    RobertaTokenizer\n",")\n","from transformers import RobertaForSequenceClassification, RobertaModelWithHeads, RobertaConfig\n","from transformers import TrainingArguments, Trainer, EvalPrediction\n","\n","from sklearn import metrics\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","\n","from transformers import EarlyStoppingCallback\n","from transformers.integrations import TensorBoardCallback\n","from tensorflow import summary\n","import tensorflow\n","%load_ext tensorboard\n","import datetime"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using device: cuda\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wwRHoyT1Kwyl"},"source":["Dataset and Tokenizers"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":163,"referenced_widgets":["7e55fa159bc34c7ca56ee215eddaaa5e","4139b521eb4647bfa32f40a9f69f6a21","3be5351a53124cb2aecfa5f27f6fcb17","12540c27ad5f4b78a7657fb1b1fe1469","fd4754ec60e44121aca94cc21d7e1627","cee0217fd43548609aa6f991ad931be8","edcb6c291411405ca7a3b72e69636b66","6bb264a03a2543bbaca480e6032457c1","7fd3d84720604e068de45772689a1eb7","aa8b8b2fff4543129ac8180398db79ad","14142725a1234b0b89ef7e3cb082d02b","57cb5cbffb19490c9acfd2d3cd3dc293","2193a2ae73f1446eb9ac63d529de8271","c872d08812f542d29f2fd5a3c34f8f38","eb49d36ef3f741da9265a0084233f0a9","a18a307d98664bce95abb2b4a2037792","9911544e46c74a8c8573beefe8cb183c","32fd8aa6a8d04e65b7c938408e1e5f5c","b6fbbf5e98cb4c818c09c96c156ceb86","709719d8086f4c7c91d4e5d9084b0780","f95c1ffd59f34926a3479f5b30839324","a79b26f4edee47a69c355f731c5549d1","6ffefd974ac845bfb7d19717121757d5","7e3849e5ed834445a1bc4c5b077ff9c7"]},"id":"tTjqSHp8IjOp","executionInfo":{"status":"ok","timestamp":1619933717094,"user_tz":-480,"elapsed":483489,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}},"outputId":"f081bb94-5203-471d-eba6-e4fdf6b9af83"},"source":["DATASET = 'imdb'\n","tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")"],"execution_count":4,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7e55fa159bc34c7ca56ee215eddaaa5e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7fd3d84720604e068de45772689a1eb7","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9911544e46c74a8c8573beefe8cb183c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355863.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RoTj34hLH6Ui","executionInfo":{"status":"ok","timestamp":1619933794815,"user_tz":-480,"elapsed":561205,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}},"outputId":"dbb81b25-70e2-4d32-fafb-973e0807710e"},"source":["print(tokenizer.bos_token_id, tokenizer.bos_token, tokenizer.eos_token_id, tokenizer.eos_token)\n","MAX_SEQUENCE_LENGTH = 512\n","\n","\n","def load_and_tokenize(url, label2id={}, count_label = 0, tokenizer=tokenizer):\n","  # tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n","  block_size=512\n","  dataframe = []\n","  with urllib.request.urlopen(url) as f:\n","    for line in f:\n","      doc = json.loads(line.decode('utf-8'))['text']\n","      tokenized_text = tokenizer(doc, max_length=MAX_SEQUENCE_LENGTH, truncation=True, padding=\"max_length\")\n","      label = json.loads(line.decode('utf-8'))['label']\n","      \n","      if label not in label2id:\n","        label2id[label] = count_label\n","        count_label +=1\n","      tokenized_text['labels'] = torch.tensor(label2id[label])\n","      tokenized_text['input_ids'] = torch.tensor(tokenized_text['input_ids'])\n","      tokenized_text['attention_mask'] = torch.tensor(tokenized_text['attention_mask'])\n","      dataframe.append(tokenized_text)\n","  return dataframe, count_label, label2id\n","\n","train,count_label, label2id = load_and_tokenize(\"https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/\"+DATASET+\"/train.jsonl\", tokenizer=tokenizer)\n","dev,count_label,label2id = load_and_tokenize(\"https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/\"+DATASET+\"/dev.jsonl\",label2id,  count_label, tokenizer=tokenizer)\n","test,count_label,label2id = load_and_tokenize(\"https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/\"+DATASET+\"/test.jsonl\",label2id,  count_label, tokenizer=tokenizer)\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["0 <s> 2 </s>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ng0MCo9NH6XJ","executionInfo":{"status":"ok","timestamp":1619933794822,"user_tz":-480,"elapsed":561211,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}}},"source":["# config"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"FKy95v85v3A4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619933794822,"user_tz":-480,"elapsed":561207,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}},"outputId":"7fe634e4-70d8-4fd0-98bf-dc8b33a74431"},"source":["train[0]\n","print(len(train))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["20000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hTNu7bBNUJ7S"},"source":["Folder to save results"]},{"cell_type":"code","metadata":{"id":"U86TlZD8UJ7X","executionInfo":{"status":"ok","timestamp":1619933794823,"user_tz":-480,"elapsed":561207,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}}},"source":["RESULTS_DIR = f\"\"\"/content/drive/My Drive/DL_Project/results/cross-task/search\"\"\""],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JAeAUGarJxb6"},"source":["General packages and functions"]},{"cell_type":"code","metadata":{"id":"LUAcaKKFJGeX","executionInfo":{"status":"ok","timestamp":1619933794824,"user_tz":-480,"elapsed":561206,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}}},"source":["from transformers import TrainingArguments, Trainer, EvalPrediction\n","def compute_accuracy(p: EvalPrediction):\n","    labels = p.label_ids\n","    preds = np.argmax(p.predictions, axis=1)\n","    acc = accuracy_score(labels, preds)\n","    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n","    return {\n","        'accuracy': acc,\n","        'f1': f1,\n","        'precision': precision,\n","        'recall': recall\n","    }\n","\n","from transformers import AdapterType, AdapterConfig"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"LXIo9sQ2M43p","executionInfo":{"status":"ok","timestamp":1619933794824,"user_tz":-480,"elapsed":561205,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}}},"source":["def run_model(hyperparams_dict, model_name=\"roberta-base\",task_name=\"myown\",adapter_name=None,adapter_config=None,seed=999):\n","    global model\n","    config = RobertaConfig.from_pretrained(\n","        model_name,\n","        num_labels=len(label2id),\n","    )\n","    model = RobertaModelWithHeads.from_pretrained(\n","        model_name,\n","        config=config,\n","    )\n","\n","    if torch.cuda.is_available():\n","      model = model.to(\"cuda\")\n","    id2label= {v: k for k, v in label2id.items()}\n","    model.load_adapter(\"/content/drive/MyDrive/DL_Project/results/amazon_base_finetune/\",adapter_type = AdapterType.text_task, config=None, model_name=\"roberta-base\", load_as=\"amazon_base_finetune\", with_head=False)\n","    model.freeze_model(True)\n","    '''\n","    if adapter_name:\n","      # add a new adapter\n","      if adapter_config:\n","        model.add_adapter(\n","            task_name,\n","            ##### remove AdapterType argument for v2 #####\n","            #AdapterType.text_task,\n","            config=adapter_config\n","        )\n","      else:\n","        model.add_adapter(\n","            task_name,\n","            ##### remove AdapterType argument for v2 #####\n","            #AdapterType.text_task \n","        )\n","      # Enable adapter training\n","      model.train_adapter([task_name])\n","      ''' \n","    # Add a matching classification head\n","    model.add_classification_head(\n","        task_name,\n","        num_labels=len(label2id),\n","        id2label=id2label,\n","        layers=2\n","      )\n","    # train, dev, test = get_datasets(tokenizer)\n","    training_args = TrainingArguments(\n","        learning_rate=hyperparams_dict['learning_rate'],\n","        num_train_epochs=hyperparams_dict['num_train_epochs'],\n","        per_device_train_batch_size=hyperparams_dict['per_device_train_batch_size'],\n","        per_device_eval_batch_size=hyperparams_dict['per_device_eval_batch_size'],\n","        logging_steps=hyperparams_dict['logging_steps'],\n","        save_steps=hyperparams_dict['save_steps'],\n","        output_dir='./models/'+task_name,\n","        overwrite_output_dir=True,\n","        do_train=True,\n","        do_eval=True,\n","        do_predict=True,\n","        evaluation_strategy='steps', # use evaluation_strategy='epoch' for v2, evaluation_strategy='step' for large dataset\n","        # The next line is important to ensure the dataset labels are properly passed to the model\n","        remove_unused_columns=False,\n","        load_best_model_at_end=True,\n","        metric_for_best_model=\"loss\",\n","        greater_is_better=False,\n","        seed=int(seed)\n","    )\n","\n","    # tensor_board = TensorBoardCallback()\n","    ##### Early Stopping #####\n","    es = EarlyStoppingCallback(early_stopping_patience=2, early_stopping_threshold=0.0)\n","    if adapter_name:\n","      trainer = Trainer(\n","          model=model,\n","          args=training_args,\n","          train_dataset=train,\n","          eval_dataset=dev,\n","          compute_metrics=compute_accuracy,\n","          callbacks=[es],\n","          adapter_names=[adapter_name]   \n","      )\n","    else:\n","      trainer = Trainer(\n","          model=model,\n","          args=training_args,\n","          train_dataset=train,\n","          eval_dataset=dev,\n","          callbacks=[es],\n","          compute_metrics=compute_accuracy\n","      )\n","    trainer.train()\n","\n","    ##### Explicitly set active adapter to pass it in model forward pass,             #####\n","    ##### otherwise the previous setting adapter_names=[adapter_name] not work for v2 #####\n","    if adapter_name:\n","      trainer.model.set_active_adapters(adapter_name)\n","    model.freeze_model(False)\n","    _, _, metrics = trainer.predict(dev)\n","    metrics['seed'] = seed\n","    dev_results.append(pd.DataFrame.from_dict(metrics, orient='index').T)\n","\n","    metrics['seed'] = seed\n","    _, _, metrics = trainer.predict(test)\n","    test_results.append(pd.DataFrame.from_dict(metrics, orient='index').T)\n","    \n","    filepath = RESULTS_DIR + \"\"\"{}_{}_{}\"\"\".format(task_name,seed,timestamp.strftime(\"%Y-%m-%dT%H_%M_%S\"))\n","    filepath = filepath + '_' + str(hyperparams_dict['learning_rate']) \\\n","                + '_' + str(hyperparams_dict['num_train_epochs']) \\\n","                + '_' + str(hyperparams_dict['per_device_train_batch_size'] ) \\\n","                + '_' + str(hyperparams_dict['per_device_eval_batch_size']) \\\n","                + '_' + str(hyperparams_dict['logging_steps']) \\\n","                + '_' + str(hyperparams_dict['save_steps'])\n","    trainer.save_model(filepath)"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CH189097M2Aq"},"source":["### Model: RoBERTa Base\n","### Task: Reviews\n","### Finetuning: Standard with classification head\n","### Adapter: None (None /Custom /Default / Houlsby / Pfeiffer)"]},{"cell_type":"code","metadata":{"id":"4lqaOie3M2Aq","executionInfo":{"status":"ok","timestamp":1619933794825,"user_tz":-480,"elapsed":561205,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}}},"source":["# MODEL_NAME = \"allenai/cs_roberta_base\"\n","MODEL_NAME = \"roberta-base\"\n","TASK_NAME = \"amazon_base_finetune\" # cit_intent_base_myownadapter / cit_intent_base_pfieffer\n","ADAPTER_NAME = \"amazon_base_finetune\" # None pfieffer / cit_intent_base_finetune\n","\n","\n","ADAPTER_CONFIG = None # leave ADAPTER_CONFIG as None to default adapter\n","# ADAPTER_CONFIG = AdapterConfig.load( # comment out if using default adapter\n","#     # adapter_args.adapter_config,\n","#     # non_linearity=adapter_args.adapter_non_linearity,\n","#     # reduction_factor=adapter_args.adapter_reduction_factor,\n","#     ADAPTER_NAME, \n","#     # non_linearity=adapter_args.adapter_non_linearity,\n","#     reduction_factor=12\n","# )\n","\n","# hyperparameters search\n","hyperparameters_dict = {'learning_rate':2e-5,'num_train_epochs':10,'per_device_train_batch_size':16,'per_device_eval_batch_size':16,'logging_steps':200,'save_steps':200} # hyperparameters for standard finetuning\n","'''\n","HYPERPARAMETERS_SEARCH = [{'learning_rate':1e-4,'num_train_epochs':10,'per_device_train_batch_size':16,'per_device_eval_batch_size':16,'logging_steps':1000,'save_steps':1000},\n","                          {'learning_rate':8e-5,'num_train_epochs':10,'per_device_train_batch_size':16,'per_device_eval_batch_size':16,'logging_steps':1000,'save_steps':1000},\n","                          {'learning_rate':2e-5,'num_train_epochs':10,'per_device_train_batch_size':16,'per_device_eval_batch_size':16,'logging_steps':1000,'save_steps':1000},\n","                          {'learning_rate':1e-4,'num_train_epochs':10,'per_device_train_batch_size':32,'per_device_eval_batch_size':32,'logging_steps':1000,'save_steps':1000},\n","                          {'learning_rate':8e-5,'num_train_epochs':10,'per_device_train_batch_size':32,'per_device_eval_batch_size':32,'logging_steps':1000,'save_steps':1000},\n","                          {'learning_rate':2e-5,'num_train_epochs':10,'per_device_train_batch_size':32,'per_device_eval_batch_size':32,'logging_steps':1000,'save_steps':1000},\n","                          ]\n","'''\n","HYPERPARAMETERS_SEARCH = [ {'learning_rate':2e-5,'num_train_epochs':10,'per_device_train_batch_size':16,'per_device_eval_batch_size':16,'logging_steps':200,'save_steps':200}]\n"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"u52XtNy1M2Aq","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["9f07fe4827dc49f5b7824253618cace8","bb94f485c18646589733d0baadf36f60","52ab9e924ad84e6cb6a52b48628fe48b","b0c89e55ff454e20b9684cfc0638b52b","7ca0e648266548598d227f62a5d0f813","1fded96945fc4fff8de855316475caf2","cea11fa54db2424bad3140fc4037c6ad","5a8b427263e948808a82b8382aa60515","d91b492a0651449db688cfd8377fa1f7","ff45bfeb88274fbb976c62bec033638f","b14c0ee666de452da2671205bf761a51","f37919463b2d4d17b2b102942d9fbeb5","033ffbedd6c14d3c98c6078289ff869e","625d450e3a884261945af98e50b80f89","4ceaa96e7e04486ca05e687fff833ceb","c6aaab789695412d99fc57e950e91234"]},"executionInfo":{"status":"ok","timestamp":1619942891030,"user_tz":-480,"elapsed":9657405,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}},"outputId":"96ba5a35-1aad-43f6-a70d-2c8bf177c855"},"source":["\n","\n","from datetime import datetime, timedelta\n","timestamp = datetime.today() + timedelta(hours=8)\n","tokenizer = RobertaTokenizer.from_pretrained(MODEL_NAME)\n","print(tokenizer.bos_token_id, tokenizer.bos_token, tokenizer.eos_token_id, tokenizer.eos_token)\n","\n","seeds = [42,1, 2]\n","dev_results = []\n","test_results = []\n","print('seeds:', seeds)\n","\n","if not ADAPTER_NAME:\n","    # if using adapter, loop by HYPERPARAMETERS_SEARCH defined above\n","    for hyperparameters_dict in HYPERPARAMETERS_SEARCH:\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        print(hyperparameters_dict)\n","        run_model(hyperparameters_dict, model_name=MODEL_NAME,task_name=TASK_NAME,adapter_name=ADAPTER_NAME,adapter_config=ADAPTER_CONFIG)\n","else: # if not using adapter, assume standard finetuning and loop by seeds\n","    for seed in seeds:\n","        print(type(int(seed)))\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        print(hyperparameters_dict)\n","        run_model(hyperparameters_dict, model_name=MODEL_NAME,task_name=TASK_NAME,adapter_name=ADAPTER_NAME,adapter_config=ADAPTER_CONFIG, seed=seed)\n","\n","dev_df = pd.concat(dev_results)\n","test_df = pd.concat(test_results)\n","\n","\n","# UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior._warn_prf(average, modifier, msg_start, len(result))\n","## some labels in y_test don't appear in y_pred. \n"],"execution_count":12,"outputs":[{"output_type":"stream","text":["0 <s> 2 </s>\n","seeds: [42, 1, 2]\n","<class 'int'>\n","{'learning_rate': 2e-05, 'num_train_epochs': 10, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 16, 'logging_steps': 200, 'save_steps': 200}\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9f07fe4827dc49f5b7824253618cace8","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d91b492a0651449db688cfd8377fa1f7","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=501200538.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='2400' max='12500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 2400/12500 32:02 < 2:14:55, 1.25 it/s, Epoch 1/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Runtime</th>\n","      <th>Samples Per Second</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>200</td>\n","      <td>0.419900</td>\n","      <td>0.291143</td>\n","      <td>0.897000</td>\n","      <td>0.896974</td>\n","      <td>0.897397</td>\n","      <td>0.897000</td>\n","      <td>92.779800</td>\n","      <td>53.891000</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.286900</td>\n","      <td>0.247901</td>\n","      <td>0.901800</td>\n","      <td>0.901795</td>\n","      <td>0.901888</td>\n","      <td>0.901800</td>\n","      <td>92.812300</td>\n","      <td>53.872000</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.269500</td>\n","      <td>0.231610</td>\n","      <td>0.906600</td>\n","      <td>0.906600</td>\n","      <td>0.906600</td>\n","      <td>0.906600</td>\n","      <td>92.815900</td>\n","      <td>53.870000</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.246600</td>\n","      <td>0.226549</td>\n","      <td>0.909000</td>\n","      <td>0.908993</td>\n","      <td>0.909121</td>\n","      <td>0.909000</td>\n","      <td>92.800300</td>\n","      <td>53.879000</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.235000</td>\n","      <td>0.222821</td>\n","      <td>0.911200</td>\n","      <td>0.911187</td>\n","      <td>0.911437</td>\n","      <td>0.911200</td>\n","      <td>92.803500</td>\n","      <td>53.877000</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.238400</td>\n","      <td>0.218206</td>\n","      <td>0.912000</td>\n","      <td>0.911985</td>\n","      <td>0.912287</td>\n","      <td>0.912000</td>\n","      <td>92.839700</td>\n","      <td>53.856000</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.209500</td>\n","      <td>0.210609</td>\n","      <td>0.914000</td>\n","      <td>0.913998</td>\n","      <td>0.914032</td>\n","      <td>0.914000</td>\n","      <td>92.857200</td>\n","      <td>53.846000</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.241100</td>\n","      <td>0.205101</td>\n","      <td>0.918000</td>\n","      <td>0.918000</td>\n","      <td>0.918000</td>\n","      <td>0.918000</td>\n","      <td>92.841200</td>\n","      <td>53.855000</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.231100</td>\n","      <td>0.204443</td>\n","      <td>0.918000</td>\n","      <td>0.917997</td>\n","      <td>0.918060</td>\n","      <td>0.918000</td>\n","      <td>92.851800</td>\n","      <td>53.849000</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.222100</td>\n","      <td>0.201450</td>\n","      <td>0.918400</td>\n","      <td>0.918399</td>\n","      <td>0.918413</td>\n","      <td>0.918400</td>\n","      <td>92.798400</td>\n","      <td>53.880000</td>\n","    </tr>\n","    <tr>\n","      <td>2200</td>\n","      <td>0.231300</td>\n","      <td>0.206261</td>\n","      <td>0.918000</td>\n","      <td>0.917983</td>\n","      <td>0.918347</td>\n","      <td>0.918000</td>\n","      <td>92.829500</td>\n","      <td>53.862000</td>\n","    </tr>\n","    <tr>\n","      <td>2400</td>\n","      <td>0.215900</td>\n","      <td>0.202375</td>\n","      <td>0.918800</td>\n","      <td>0.918793</td>\n","      <td>0.918942</td>\n","      <td>0.918800</td>\n","      <td>92.821400</td>\n","      <td>53.867000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='1876' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [313/313 09:17]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["<class 'int'>\n","{'learning_rate': 2e-05, 'num_train_epochs': 10, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 16, 'logging_steps': 200, 'save_steps': 200}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='4000' max='12500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 4000/12500 53:22 < 1:53:27, 1.25 it/s, Epoch 3/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Runtime</th>\n","      <th>Samples Per Second</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>200</td>\n","      <td>0.443300</td>\n","      <td>0.303044</td>\n","      <td>0.895000</td>\n","      <td>0.894952</td>\n","      <td>0.895725</td>\n","      <td>0.895000</td>\n","      <td>92.917500</td>\n","      <td>53.811000</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.283400</td>\n","      <td>0.250931</td>\n","      <td>0.901200</td>\n","      <td>0.901191</td>\n","      <td>0.901348</td>\n","      <td>0.901200</td>\n","      <td>92.913300</td>\n","      <td>53.814000</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.258700</td>\n","      <td>0.234877</td>\n","      <td>0.906800</td>\n","      <td>0.906794</td>\n","      <td>0.906904</td>\n","      <td>0.906800</td>\n","      <td>92.856400</td>\n","      <td>53.847000</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.247600</td>\n","      <td>0.226096</td>\n","      <td>0.909000</td>\n","      <td>0.908995</td>\n","      <td>0.909090</td>\n","      <td>0.909000</td>\n","      <td>92.892400</td>\n","      <td>53.826000</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.255300</td>\n","      <td>0.219423</td>\n","      <td>0.911600</td>\n","      <td>0.911599</td>\n","      <td>0.911621</td>\n","      <td>0.911600</td>\n","      <td>92.861900</td>\n","      <td>53.843000</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.241300</td>\n","      <td>0.218443</td>\n","      <td>0.912400</td>\n","      <td>0.912389</td>\n","      <td>0.912607</td>\n","      <td>0.912400</td>\n","      <td>92.891800</td>\n","      <td>53.826000</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.229200</td>\n","      <td>0.208382</td>\n","      <td>0.915400</td>\n","      <td>0.915400</td>\n","      <td>0.915402</td>\n","      <td>0.915400</td>\n","      <td>92.901700</td>\n","      <td>53.820000</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.227000</td>\n","      <td>0.205543</td>\n","      <td>0.917200</td>\n","      <td>0.917200</td>\n","      <td>0.917201</td>\n","      <td>0.917200</td>\n","      <td>92.876100</td>\n","      <td>53.835000</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.230800</td>\n","      <td>0.203345</td>\n","      <td>0.917400</td>\n","      <td>0.917400</td>\n","      <td>0.917401</td>\n","      <td>0.917400</td>\n","      <td>92.883000</td>\n","      <td>53.831000</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.211000</td>\n","      <td>0.203568</td>\n","      <td>0.918800</td>\n","      <td>0.918798</td>\n","      <td>0.918832</td>\n","      <td>0.918800</td>\n","      <td>92.901500</td>\n","      <td>53.820000</td>\n","    </tr>\n","    <tr>\n","      <td>2200</td>\n","      <td>0.249900</td>\n","      <td>0.201997</td>\n","      <td>0.918800</td>\n","      <td>0.918793</td>\n","      <td>0.918942</td>\n","      <td>0.918800</td>\n","      <td>92.928800</td>\n","      <td>53.805000</td>\n","    </tr>\n","    <tr>\n","      <td>2400</td>\n","      <td>0.219500</td>\n","      <td>0.200220</td>\n","      <td>0.919800</td>\n","      <td>0.919797</td>\n","      <td>0.919856</td>\n","      <td>0.919800</td>\n","      <td>92.872400</td>\n","      <td>53.837000</td>\n","    </tr>\n","    <tr>\n","      <td>2600</td>\n","      <td>0.215600</td>\n","      <td>0.198253</td>\n","      <td>0.919400</td>\n","      <td>0.919399</td>\n","      <td>0.919424</td>\n","      <td>0.919400</td>\n","      <td>92.876100</td>\n","      <td>53.835000</td>\n","    </tr>\n","    <tr>\n","      <td>2800</td>\n","      <td>0.213900</td>\n","      <td>0.196747</td>\n","      <td>0.920600</td>\n","      <td>0.920600</td>\n","      <td>0.920601</td>\n","      <td>0.920600</td>\n","      <td>92.884000</td>\n","      <td>53.831000</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.222200</td>\n","      <td>0.195916</td>\n","      <td>0.920800</td>\n","      <td>0.920799</td>\n","      <td>0.920813</td>\n","      <td>0.920800</td>\n","      <td>92.867000</td>\n","      <td>53.840000</td>\n","    </tr>\n","    <tr>\n","      <td>3200</td>\n","      <td>0.200100</td>\n","      <td>0.197292</td>\n","      <td>0.920400</td>\n","      <td>0.920398</td>\n","      <td>0.920453</td>\n","      <td>0.920400</td>\n","      <td>92.860400</td>\n","      <td>53.844000</td>\n","    </tr>\n","    <tr>\n","      <td>3400</td>\n","      <td>0.221800</td>\n","      <td>0.194880</td>\n","      <td>0.921200</td>\n","      <td>0.921198</td>\n","      <td>0.921253</td>\n","      <td>0.921200</td>\n","      <td>92.870800</td>\n","      <td>53.838000</td>\n","    </tr>\n","    <tr>\n","      <td>3600</td>\n","      <td>0.220700</td>\n","      <td>0.193355</td>\n","      <td>0.922200</td>\n","      <td>0.922199</td>\n","      <td>0.922220</td>\n","      <td>0.922200</td>\n","      <td>92.862300</td>\n","      <td>53.843000</td>\n","    </tr>\n","    <tr>\n","      <td>3800</td>\n","      <td>0.222400</td>\n","      <td>0.194922</td>\n","      <td>0.921600</td>\n","      <td>0.921596</td>\n","      <td>0.921678</td>\n","      <td>0.921600</td>\n","      <td>92.846100</td>\n","      <td>53.853000</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.204300</td>\n","      <td>0.196623</td>\n","      <td>0.922000</td>\n","      <td>0.921995</td>\n","      <td>0.922108</td>\n","      <td>0.922000</td>\n","      <td>92.852300</td>\n","      <td>53.849000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='1876' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [313/313 09:17]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["<class 'int'>\n","{'learning_rate': 2e-05, 'num_train_epochs': 10, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 16, 'logging_steps': 200, 'save_steps': 200}\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='2800' max='12500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 2800/12500 37:22 < 2:09:33, 1.25 it/s, Epoch 2/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>Runtime</th>\n","      <th>Samples Per Second</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>200</td>\n","      <td>0.428900</td>\n","      <td>0.292717</td>\n","      <td>0.896000</td>\n","      <td>0.895984</td>\n","      <td>0.896244</td>\n","      <td>0.896000</td>\n","      <td>92.887300</td>\n","      <td>53.829000</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.299200</td>\n","      <td>0.252620</td>\n","      <td>0.901200</td>\n","      <td>0.901182</td>\n","      <td>0.901497</td>\n","      <td>0.901200</td>\n","      <td>92.870800</td>\n","      <td>53.838000</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.245000</td>\n","      <td>0.233383</td>\n","      <td>0.905800</td>\n","      <td>0.905800</td>\n","      <td>0.905801</td>\n","      <td>0.905800</td>\n","      <td>92.875600</td>\n","      <td>53.835000</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.254500</td>\n","      <td>0.233064</td>\n","      <td>0.907400</td>\n","      <td>0.907381</td>\n","      <td>0.907729</td>\n","      <td>0.907400</td>\n","      <td>92.881300</td>\n","      <td>53.832000</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.256700</td>\n","      <td>0.218171</td>\n","      <td>0.911600</td>\n","      <td>0.911599</td>\n","      <td>0.911621</td>\n","      <td>0.911600</td>\n","      <td>92.843500</td>\n","      <td>53.854000</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.245600</td>\n","      <td>0.214102</td>\n","      <td>0.913600</td>\n","      <td>0.913597</td>\n","      <td>0.913652</td>\n","      <td>0.913600</td>\n","      <td>92.883700</td>\n","      <td>53.831000</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.221100</td>\n","      <td>0.212339</td>\n","      <td>0.914200</td>\n","      <td>0.914196</td>\n","      <td>0.914272</td>\n","      <td>0.914200</td>\n","      <td>92.864700</td>\n","      <td>53.842000</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.223500</td>\n","      <td>0.208090</td>\n","      <td>0.915600</td>\n","      <td>0.915597</td>\n","      <td>0.915668</td>\n","      <td>0.915600</td>\n","      <td>92.883000</td>\n","      <td>53.831000</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.220500</td>\n","      <td>0.204238</td>\n","      <td>0.916200</td>\n","      <td>0.916200</td>\n","      <td>0.916203</td>\n","      <td>0.916200</td>\n","      <td>92.875100</td>\n","      <td>53.836000</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.221500</td>\n","      <td>0.201339</td>\n","      <td>0.919000</td>\n","      <td>0.919000</td>\n","      <td>0.919000</td>\n","      <td>0.919000</td>\n","      <td>92.857700</td>\n","      <td>53.846000</td>\n","    </tr>\n","    <tr>\n","      <td>2200</td>\n","      <td>0.224400</td>\n","      <td>0.201512</td>\n","      <td>0.919000</td>\n","      <td>0.918997</td>\n","      <td>0.919056</td>\n","      <td>0.919000</td>\n","      <td>92.856200</td>\n","      <td>53.847000</td>\n","    </tr>\n","    <tr>\n","      <td>2400</td>\n","      <td>0.242600</td>\n","      <td>0.198571</td>\n","      <td>0.919400</td>\n","      <td>0.919399</td>\n","      <td>0.919419</td>\n","      <td>0.919400</td>\n","      <td>92.834400</td>\n","      <td>53.859000</td>\n","    </tr>\n","    <tr>\n","      <td>2600</td>\n","      <td>0.233900</td>\n","      <td>0.199574</td>\n","      <td>0.920800</td>\n","      <td>0.920792</td>\n","      <td>0.920968</td>\n","      <td>0.920800</td>\n","      <td>92.839200</td>\n","      <td>53.857000</td>\n","    </tr>\n","    <tr>\n","      <td>2800</td>\n","      <td>0.192100</td>\n","      <td>0.200734</td>\n","      <td>0.919200</td>\n","      <td>0.919194</td>\n","      <td>0.919318</td>\n","      <td>0.919200</td>\n","      <td>92.840200</td>\n","      <td>53.856000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='1876' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [313/313 09:17]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"g5yMbjcAM2Ar","colab":{"base_uri":"https://localhost:8080/","height":832},"executionInfo":{"status":"ok","timestamp":1619942891033,"user_tz":-480,"elapsed":9657403,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}},"outputId":"2d95ae91-089c-4937-90d6-4e6e624a8e6a"},"source":["display(dev_df)\n","display(dev_df.describe())\n","\n","display(test_df)\n","display(test_df.describe())"],"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>test_loss</th>\n","      <th>test_accuracy</th>\n","      <th>test_f1</th>\n","      <th>test_precision</th>\n","      <th>test_recall</th>\n","      <th>test_runtime</th>\n","      <th>test_samples_per_second</th>\n","      <th>test_mem_cpu_alloc_delta</th>\n","      <th>test_mem_gpu_alloc_delta</th>\n","      <th>test_mem_cpu_peaked_delta</th>\n","      <th>test_mem_gpu_peaked_delta</th>\n","      <th>seed</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.201450</td>\n","      <td>0.9184</td>\n","      <td>0.918399</td>\n","      <td>0.918413</td>\n","      <td>0.9184</td>\n","      <td>92.8535</td>\n","      <td>53.848</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>807131648.0</td>\n","      <td>42.0</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>0.193355</td>\n","      <td>0.9222</td>\n","      <td>0.922199</td>\n","      <td>0.922220</td>\n","      <td>0.9222</td>\n","      <td>92.9087</td>\n","      <td>53.816</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>833926656.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>0.198571</td>\n","      <td>0.9194</td>\n","      <td>0.919399</td>\n","      <td>0.919419</td>\n","      <td>0.9194</td>\n","      <td>92.8675</td>\n","      <td>53.840</td>\n","      <td>323584.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>780431360.0</td>\n","      <td>2.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   test_loss  test_accuracy  ...  test_mem_gpu_peaked_delta  seed\n","0   0.201450         0.9184  ...                807131648.0  42.0\n","0   0.193355         0.9222  ...                833926656.0   1.0\n","0   0.198571         0.9194  ...                780431360.0   2.0\n","\n","[3 rows x 12 columns]"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>test_loss</th>\n","      <th>test_accuracy</th>\n","      <th>test_f1</th>\n","      <th>test_precision</th>\n","      <th>test_recall</th>\n","      <th>test_runtime</th>\n","      <th>test_samples_per_second</th>\n","      <th>test_mem_cpu_alloc_delta</th>\n","      <th>test_mem_gpu_alloc_delta</th>\n","      <th>test_mem_cpu_peaked_delta</th>\n","      <th>test_mem_gpu_peaked_delta</th>\n","      <th>seed</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>3.000000</td>\n","      <td>3.00000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.00000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.000000e+00</td>\n","      <td>3.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.197792</td>\n","      <td>0.92000</td>\n","      <td>0.919999</td>\n","      <td>0.920017</td>\n","      <td>0.92000</td>\n","      <td>92.876567</td>\n","      <td>53.834667</td>\n","      <td>107861.333333</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.071632e+08</td>\n","      <td>15.000000</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.004103</td>\n","      <td>0.00197</td>\n","      <td>0.001970</td>\n","      <td>0.001972</td>\n","      <td>0.00197</td>\n","      <td>0.028695</td>\n","      <td>0.016653</td>\n","      <td>186821.309505</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.674766e+07</td>\n","      <td>23.388031</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.193355</td>\n","      <td>0.91840</td>\n","      <td>0.918399</td>\n","      <td>0.918413</td>\n","      <td>0.91840</td>\n","      <td>92.853500</td>\n","      <td>53.816000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>7.804314e+08</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.195963</td>\n","      <td>0.91890</td>\n","      <td>0.918899</td>\n","      <td>0.918916</td>\n","      <td>0.91890</td>\n","      <td>92.860500</td>\n","      <td>53.828000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>7.937815e+08</td>\n","      <td>1.500000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.198571</td>\n","      <td>0.91940</td>\n","      <td>0.919399</td>\n","      <td>0.919419</td>\n","      <td>0.91940</td>\n","      <td>92.867500</td>\n","      <td>53.840000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.071316e+08</td>\n","      <td>2.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.200010</td>\n","      <td>0.92080</td>\n","      <td>0.920799</td>\n","      <td>0.920819</td>\n","      <td>0.92080</td>\n","      <td>92.888100</td>\n","      <td>53.844000</td>\n","      <td>161792.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.205292e+08</td>\n","      <td>22.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>0.201450</td>\n","      <td>0.92220</td>\n","      <td>0.922199</td>\n","      <td>0.922220</td>\n","      <td>0.92220</td>\n","      <td>92.908700</td>\n","      <td>53.848000</td>\n","      <td>323584.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.339267e+08</td>\n","      <td>42.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       test_loss  test_accuracy  ...  test_mem_gpu_peaked_delta       seed\n","count   3.000000        3.00000  ...               3.000000e+00   3.000000\n","mean    0.197792        0.92000  ...               8.071632e+08  15.000000\n","std     0.004103        0.00197  ...               2.674766e+07  23.388031\n","min     0.193355        0.91840  ...               7.804314e+08   1.000000\n","25%     0.195963        0.91890  ...               7.937815e+08   1.500000\n","50%     0.198571        0.91940  ...               8.071316e+08   2.000000\n","75%     0.200010        0.92080  ...               8.205292e+08  22.000000\n","max     0.201450        0.92220  ...               8.339267e+08  42.000000\n","\n","[8 rows x 12 columns]"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>test_loss</th>\n","      <th>test_accuracy</th>\n","      <th>test_f1</th>\n","      <th>test_precision</th>\n","      <th>test_recall</th>\n","      <th>test_runtime</th>\n","      <th>test_samples_per_second</th>\n","      <th>test_mem_cpu_alloc_delta</th>\n","      <th>test_mem_gpu_alloc_delta</th>\n","      <th>test_mem_cpu_peaked_delta</th>\n","      <th>test_mem_gpu_peaked_delta</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.200782</td>\n","      <td>0.92052</td>\n","      <td>0.920519</td>\n","      <td>0.920537</td>\n","      <td>0.92052</td>\n","      <td>463.9852</td>\n","      <td>53.881</td>\n","      <td>638976.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.132771e+09</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>0.190892</td>\n","      <td>0.92512</td>\n","      <td>0.925120</td>\n","      <td>0.925123</td>\n","      <td>0.92512</td>\n","      <td>464.3886</td>\n","      <td>53.834</td>\n","      <td>540672.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.340050e+08</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>0.197329</td>\n","      <td>0.92188</td>\n","      <td>0.921879</td>\n","      <td>0.921898</td>\n","      <td>0.92188</td>\n","      <td>464.1629</td>\n","      <td>53.860</td>\n","      <td>561152.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.341535e+08</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   test_loss  ...  test_mem_gpu_peaked_delta\n","0   0.200782  ...               1.132771e+09\n","0   0.190892  ...               8.340050e+08\n","0   0.197329  ...               8.341535e+08\n","\n","[3 rows x 11 columns]"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>test_loss</th>\n","      <th>test_accuracy</th>\n","      <th>test_f1</th>\n","      <th>test_precision</th>\n","      <th>test_recall</th>\n","      <th>test_runtime</th>\n","      <th>test_samples_per_second</th>\n","      <th>test_mem_cpu_alloc_delta</th>\n","      <th>test_mem_gpu_alloc_delta</th>\n","      <th>test_mem_cpu_peaked_delta</th>\n","      <th>test_mem_gpu_peaked_delta</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.196334</td>\n","      <td>0.922507</td>\n","      <td>0.922506</td>\n","      <td>0.922519</td>\n","      <td>0.922507</td>\n","      <td>464.178900</td>\n","      <td>53.858333</td>\n","      <td>580266.666667</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>9.336431e+08</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.005019</td>\n","      <td>0.002363</td>\n","      <td>0.002364</td>\n","      <td>0.002355</td>\n","      <td>0.002363</td>\n","      <td>0.202175</td>\n","      <td>0.023544</td>\n","      <td>51864.698643</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.724497e+08</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.190892</td>\n","      <td>0.920520</td>\n","      <td>0.920519</td>\n","      <td>0.920537</td>\n","      <td>0.920520</td>\n","      <td>463.985200</td>\n","      <td>53.834000</td>\n","      <td>540672.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.340050e+08</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.194111</td>\n","      <td>0.921200</td>\n","      <td>0.921199</td>\n","      <td>0.921217</td>\n","      <td>0.921200</td>\n","      <td>464.074050</td>\n","      <td>53.847000</td>\n","      <td>550912.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.340792e+08</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.197329</td>\n","      <td>0.921880</td>\n","      <td>0.921879</td>\n","      <td>0.921898</td>\n","      <td>0.921880</td>\n","      <td>464.162900</td>\n","      <td>53.860000</td>\n","      <td>561152.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.341535e+08</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.199055</td>\n","      <td>0.923500</td>\n","      <td>0.923500</td>\n","      <td>0.923510</td>\n","      <td>0.923500</td>\n","      <td>464.275750</td>\n","      <td>53.870500</td>\n","      <td>600064.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>9.834621e+08</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>0.200782</td>\n","      <td>0.925120</td>\n","      <td>0.925120</td>\n","      <td>0.925123</td>\n","      <td>0.925120</td>\n","      <td>464.388600</td>\n","      <td>53.881000</td>\n","      <td>638976.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.132771e+09</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       test_loss  ...  test_mem_gpu_peaked_delta\n","count   3.000000  ...               3.000000e+00\n","mean    0.196334  ...               9.336431e+08\n","std     0.005019  ...               1.724497e+08\n","min     0.190892  ...               8.340050e+08\n","25%     0.194111  ...               8.340792e+08\n","50%     0.197329  ...               8.341535e+08\n","75%     0.199055  ...               9.834621e+08\n","max     0.200782  ...               1.132771e+09\n","\n","[8 rows x 11 columns]"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"0pHUcyA9gIfL"},"source":["Saving results"]},{"cell_type":"code","metadata":{"id":"dmgfsM3OM3wT","executionInfo":{"status":"ok","timestamp":1619942891036,"user_tz":-480,"elapsed":9657404,"user":{"displayName":"Ng WX","photoUrl":"https://lh4.googleusercontent.com/-AXn_6O-ootU/AAAAAAAAAAI/AAAAAAAABCs/TtxB7rBRgS4/s64/photo.jpg","userId":"17422648075664283449"}}},"source":[""],"execution_count":13,"outputs":[]}]}